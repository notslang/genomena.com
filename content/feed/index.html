<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Genomena</title>
	<atom:link href="/feed/" rel="self" type="application/rss+xml" />
	<link>http://genomena.com</link>
	<description>As genomes evolve, so does the world.</description>
	<lastBuildDate>Wed, 01 Feb 2017 02:46:36 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.5.6</generator>
	<item>
	<title>Threesomics</title>
	<link>/2014/04/06/threesomics/</link>
	<comments>/2014/04/06/threesomics/#respond</comments>
	<pubDate>Sun, 06 Apr 2014 11:57:03 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genomes and health]]></category>

	<guid isPermaLink="false">/?p=65</guid>
	<description><![CDATA[Her heart beat in frightened counterpoint to the rhythm of the mitochondrion. &#8212; Madeleine l&#8217;Engle, A Wind in the Door (1973) As you&#8217;ve likely heard,...]]></description>
		<content:encoded><![CDATA[<blockquote><p>
  Her heart beat in frightened counterpoint<br />
  to the rhythm of the mitochondrion.<br />
  &#8212; Madeleine l&#8217;Engle, <em>A Wind in the Door</em> (1973)
</p></blockquote>
<p>As you&#8217;ve likely heard, we&#8217;re doomed. Earth will soon be overrun by babies with three – <em><a href="http://onpoint.wbur.org/2014/02/26/mitochondria-genetically-modified-babies-dna">three</a></em> – biological parents each.</p>
<p>More parents per child will mean, of course, more <a href="http://www.cnn.com/2009/LIVING/02/04/girl.scout.cookie.ethics/index.html">colleagues hawking Girl Scout cookies</a> next year. Facebook friend feeds, along with all organized toddler soccer, will become even less tolerable. If the news pleased anyone, you&#8217;d think it might be people who fret about families with <a href="http://www.linacre.org/clone2.html">too few parents</a>. But it turns out that even they&#8217;re upset, now that children might have <a href="http://archive.catholicherald.co.uk/article/4th-september-2009/3/bioethicists-criticise-procedure-involving-three-p">too <em>many</em></a> genetically invested adults caring about them.</p>
<p>All this because <a href="http://www.scientificamerican.com/article/making-babies-with-3-genetic-parents-gets-fda-hearing/">American</a> and <a href="http://www.reuters.com/article/2014/02/27/us-ivf-3parent-idUSBREA1Q12420140227">British</a> regulators may endorse women replacing faulty <a href="http://wikipedia.org/mitochondria">mitochondria</a> in their eggs, with working ones from other women, in order to have healthy kids. As fertilizing eggs <a href="http://news.bbc.co.uk/2/hi/health/1431489.stm">still</a> requires sperm, such <a href="http://en.wikipedia.org/wiki/Three-parent_baby">mitochondrial rescue</a> really does make kids with three genomic parents. And yes, it willfully and heritably modifies human genomes in doing so.</p>
<p>But while those facts make juicy <a href="http://www.nytimes.com/2014/02/24/opinion/genetically-modified-babies.html">headlines</a>, they&#8217;re actually <a href="http://www.nytimes.com/2001/05/05/health/05DNA.html">old news</a>. For a start, note that <em>every</em> way to have kids (except <a href="/reproductive-technology-article/reproductive-cloning/reproductive-cloning-intro/">cloning</a>) heritably modifies genomes &#8212; and does so, in part, to favor specific traits that parents like (in each other). And among those various ways to breed, Parenting v3, in particular, debuted not last month (or in the future) but in <a href="http://www.thelancet.com/journals/lancet/article/PIIS0140-6736(05)62353-7/fulltext">1997</a>.</p>
<p>Early three-parent outcomes were <a href="http://humupd.oxfordjournals.org/content/7/4/428.long">reviewed</a> in 2001, when the FDA slowed things down in the US, to watch how healthy the first such toddlers stayed over time. Answer? Apparently as <a href="http://well.blogs.nytimes.com/2013/12/16/three-biological-parents-and-a-baby/?_php=true&amp;_type=blogs&amp;_r=0">healthy</a> as any other anecdotally small sample of teenagers. And now, with some of those kids heading to college, regulators are appraising <a href="http://www.fda.gov/downloads/advisorycommittees/committeesmeetingmaterials/bloodvaccinesandotherbiologics/cellulartissueandgenetherapiesadvisorycommittee/ucm385461.pdf">a new version</a> of mitochondrial rescue that cuts one of original method&#8217;s already evidently low risks.[1]</p>
<p>Ok, so three-parent baby stories apparently pop up like cicadas, every ~13 or 17 years, for a new chorus of buzz. With them, us, and regulators all brooding anew, keep a few points in mind:</p>
<h2><em>Every</em> human genome unites many parents.</h2>
<p>If you worry that kids with three parents are somehow an affront to nature, remember that your own genome melds the DNA of not just three, but four other people. You call them grandparents.</p>
<p>Well, actually, your genome comprises DNA from eight people: your great-grand-parents.</p>
<p>Ok, wait, it&#8217;s really sixteen&#8230; You get the point. Formally, mitochondrial rescue (and any other trick to make a <a href="http://wikipedia.org/zygote">zygote</a> from more than two people&#8217;s cells) just speeds up what villages have long done by serially remixing DNA in batch after batch of kids.</p>
<p>You may scoff at likening earlier generations of forebears to parents. But genealogically, the latter just bundle up the former. And here&#8217;s the bottom line: <em>Your average great-great-great-great-great-great-great-great-great-great-grandparent gave you roughly a hundred times more DNA than a mitochondrial donor gives her three-parent child.</em></p>
<p>By that measure,[2] your own birth should have been tabloid news (&#8216;4096 parents!&#8217;). That it wasn&#8217;t so says much less about genetic inheritance than, perhaps, about our tangled obsessions with sex and technology.</p>
<h2>Yes, mitochondria are heritable. Sometimes.</h2>
<p>Future lab methods may let men transmit mitochondria to kids. But for now only women can do so. As such, only about half of kids born today (whether conventionally or by mitochondrial rescue) can pass on mitochondria at all.</p>
<p>So yes, mitochondrial rescue heritably alters genomes, but only for daughters &#8212; and specifically, those who grow up healthy enough to securely have kids of their own. Which circularly underscores the point of effective mitochondrial rescue in the first place.[3]</p>
<p>And more pointedly, old-fashioned two-parent breeding heritably alters genomes too (if that means we should ban sex, well, good luck to us&#8230;).</p>
<h2>Donors and their kids are just like cousins, via time travel.</h2>
<p>A key twist to mitochondrial rescue is that mothers hand down their mitochondrial chromosomes <em>whole</em>, without the <a href="http://en.wikipedia.org/wiki/Genetic_recombination">recombination</a> that, over generations, splits other chromosomes to smithereens. As such, your own ring of mitochondrial DNA is a tiny but sturdy heirloom, inherited &#8212; typically fully intact[4] &#8212; from a long chain of foremothers, the earliest of whom have given you <em>nothing</em> more of their genomes.</p>
<p>Which makes mitochondrial rescue like sneaking several centuries up into your family tree, with some grafting shears, to set up the last such woman&#8217;s father with a different mate. But crucially, and unlike most time travel, this trip brings no (great&#8230;) <a href="http://en.wikipedia.org/wiki/Grandfather_paradox">grandfather paradox</a> for you: beyond swapping your mitochondrial type, it would leave <em>no</em> trace in your genome.[5]</p>
<p>In fact, it would leave you only faintly related &#8212; <em>exactly</em> like a distant <a href="https://www.umanitoba.ca/faculties/arts/anthropology/tutor/fundamentals/m-pline.html">matrilineal</a> cousin &#8212; to your mitochondrial parent. Such gossamer kinship doesn&#8217;t typify parents and children today, but we know it well in adoptive and extended families. And as reproductive technologies advance, we can handle such new kinds of relationships just fine. If you aren&#8217;t horrified by cousins, don&#8217;t lose sleep over three-parent kids.</p>
<h2>For those who most want it, mitochondrial rescue is much <em>safer</em> than conventional sex.</h2>
<p>Methods of mitochondrial rescue carry three main kinds of risk: needle damage to cells; nucleus-cytoplasm incompatibility; and loss of transferred mitochondria. You can read about them in footnotes[6] below, but the evidence suggests that they&#8217;re each small.</p>
<p>As such, if you would ban mitochondrial rescue because it <em>might</em> make sick kids, you really should speak up to ban women with some mitochondrial diseases from having kids at all.[7] Because those born conventionally <em>will</em> be sick.</p>
<p>Mitochondrial rescue aims to give a child, whom a woman has freely decided to bear (a right that most societies recognize), a good chance at a healthy life at all. As such, rescue is simply some people&#8217;s <em>safest</em> way to have a baby &#8212; or to be born.[8]</p>
<h2>This is about mate choice.</h2>
<p>In discussing reproductive health, we often use &#8216;choice&#8217; as a euphemism for abortion. But choice is a broader ideal in family policy, as strides in marriage and adoption law in many countries highlight.</p>
<p>Yes, mitochondrial rescue uses fancy tools to remix genomes, splicing our family trees in ways that might surprise the ancestors involved. But it does so for an age-old need that they&#8217;d readily understand: to let people find compatible mates. That is, having a healthy child means, for some women, picking two mates: one to provide working mitochondria, and another to provide a male-<a href="http://en.wikipedia.org/wiki/Genomic_imprinting">imprinted</a> copy of each nuclear chromosome.</p>
<p>As ever, such mates don&#8217;t have to live together. They are, most simply, adults who agree to mingle DNA &#8212; a choice that we protect in everyday sexual freedom, egg and sperm banking, marriage, and other settings. And in mitochondrial rescue the three people who mate do so specifically for a potential child&#8217;s well-being; if only the same could be said of every conventional pregnancy.</p>
<h2>Methods make real people.</h2>
<p>Barring an apocalypse, reproductive technology will likely go far beyond mitochondrial rescue. We may see kids born with no new mating at all (clones) &#8212; and kids born to sets of <em>many</em> mates (more than just three). We may find ways for people of <em>only</em> one sex to have kids together, by <a href="http://en.wikipedia.org/wiki/Genomic_imprinting">epigenetically modifying</a> chromosomes. And we may start <a href="http://en.wikipedia.org/wiki/CRISPR">editing human genomes</a>, letter by DNA letter.</p>
<p>Such breakthroughs, like any technology, can help and hurt people. Many kids will grow up in loving families who otherwise couldn&#8217;t have had them. But others will suffer from adults&#8217; hubris (&#8216;<em>Editing that <a href="http://wikipedia.org/codon">codon</a> didn&#8217;t do what we expected&#8230;</em>&#8216;), <a href="http://www.thisamericanlife.org/radio-archives/episode/291/reunited-and-it-feels-so-good">unfair demands</a> (&#8216;<em>My clone will be the violinist I could have been&#8230;</em>&#8216;), or even crass neglect (&#8216;<em>Ladies and gentlemen, the 2020 Superbowl Champions&#8217; commemorative child&#8230;&#8217;</em>).</p>
<p>Having kids has always allowed harmful choices, of course. So new ways to breed, giving us often foolish adults more options, stand to steepen some already slippery slopes. But a bigger question will continue to loom: how we treat each new child, regardless of how (s)he came to be. And on that front, fretting about methods that are medically useful, <a href="http://blogs.law.stanford.edu/lawandbiosciences/2014/03/02/heather-has-three-parents/">but socially novel</a>, risks stigmatizing real people born by them (think of prejudices long faced by people born outside conventional bounds of marriage or ethnicity&#8230;).</p>
<p>Moreover, such stigma can, in turn, deepen healthcare inequity, by discouraging insurers from covering needed procedures. Our track record there is mixed: <a href="http://en.wikipedia.org/wiki/In_vitro_fertilisation">IVF</a> has become common, and its beneficiaries may now face little societal prejudice; but in some places it&#8217;s hard to find <a href="http://www.ncsl.org/research/health/insurance-coverage-for-infertility-laws.aspx">insurance for it</a>. As such, mitochondrial rescue may be a good test case of how we welcome people born by methods that tinker ever more deeply with how we&#8217;re made, in order to have healthier kids.</p>
<p>Those three-parent kids are here among us already. They&#8217;ve celebrated many birthdays, and perhaps some quinceañeras and <a href="http://en.wikipedia.org/wiki/Bar_and_Bat_Mitzvah">bnei mitsva</a>, the latter from Hebrew for &#8216;children of a good deed&#8217;. Extra parents may not, of course, mean extra party gifts; but reaching such milestones, in good health, seems reason to celebrate.</p>
<p>A good deed, indeed.</p>
<p><img src="/wp-content/uploads/2014/04/LineOfDescent.jpg" alt="Line of descent, London. (image by Nathaniel Pearson)" /></p>
<p>Line of descent, London. (image by Nathaniel Pearson)</p>
<p>[l] The new methods reduce the chance that any of the original, faulty mitochondria remain in the developing child&#8217;s body.</p>
<p>[2] Some age-old phenomena can let one foreparent contribute even more than usual to your genome: there&#8217;s inbreeding, of course &#8212; but also <a href="http://wikipedia.org/uniparental_disomy">uniparental disomy</a>, where, by fluke of DNA replication in germline or early embryonic cells, both of a child&#8217;s copies of a given chromosome come from the same parent. In extreme such cases, a grandmother can provide more than a third of her grandson&#8217;s genome.</p>
<p>And that leaves aside other ways in which we&#8217;re already walking mixtures of cells from various parents, via maternal-fetal microchimerism, organ donation, and so forth&#8230;</p>
<p>[3] Some women born by rescue may even choose to swap their <em>own</em> kids&#8217; mitochondria &#8212; perhaps even back to an earlier family haplotype, if particular mitochondrial diseases are otherwise readily curable a generation from now.</p>
<p>[4] New mutation, of course, can alter the heirloom as it&#8217;s handed down &#8212; sometimes causing the grave mitochondrial disease that makes mitochondrial rescue sensible.</p>
<p>[5] As such, a genome made by mitochondrial rescue looks much like any other: scanning just your own DNA, we couldn&#8217;t confidently say whether or not you were born by mitochondrial rescue.</p>
<p>By contrast, if we instead replaced one of your long autosomes &#8212; say, a copy of chromosome 1 &#8212; you <em>might</em> look obviously triparental, if your parents&#8217; ancestries varied so much that conventional two-parent breeding couldn&#8217;t plausibly have given you exactly one whole long autosome, but nothing else, from a particular ancestral population</p>
<p>[6] Foreseeable risks in mitochondrial rescue include</p>
<h2>Needle damage</h2>
<p>Tinkering with a cell can, of course, harm membranes, chromosomes, or otherwise components. While it&#8217;s a mechanistic stretch, such damage could in principle affect tissues descended from the originally altered cell, leaving a child sick in ways tracing not to mitochondria themselves, but just to the nano-surgery needed to transplant them.</p>
<p>As in macro-scale surgery, we weigh such procedural risk against likely benefit. And by that measure, mitochondrial rescue works well: so far, kids born by it show no problems attributable to needle damage, and overall tend to be as healthy as typical kids &#8212; which is also, of course, far healthier than they would have otherwise been.</p>
<h2>Incompatibility</h2>
<p>All methods of mitochondrial rescue entail separating an egg&#8217;s long chromosomes from some or all of its <em>cytoplasm</em> (the rest of its cellular guts, including mitochondria with their tiny chromosomes). The idea is to then pool healthy cytoplasm with the long chromosomes of a second, already fertilized egg. In a very loose everyday analogy, picture separating a chicken egg&#8217;s yolk and whites, in order to put whites together with a new yolk.</p>
<p>But even after an egg&#8217;s chromosomes are removed, its cytoplasm reverberates with chemical crosstalk from all of them, including commands to make so-much of specific proteins and other important molecules. When that chatter bathes new chromosomes, of the child-to-be, some of those commands may help the cell thrive (which is the point of mitochondrial transfer). But other commands may, in principle, go awry if they&#8217;re out of sync with other messages in the newly formed cell, or when they&#8217;re parsed through DNA spellings in the new nucleus that differ from those of the chromosomes that sent them.</p>
<p>While we can&#8217;t yet track (let alone understand or modify) all the messages in question, known examples of such problematic messaging are scarce; and their effects would likely be much milder than those of the original mitochondrial disease that rescue served to prevent.</p>
<p>In future, we may start to make zygotes by transferring nuclear chromosomes from cells other than other fertilized eggs (or sperm themselves). In such methods, we&#8217;ll need to carefully steward chemical flags, called epigenetic marks, that govern when particular genome segments are read. Patterns of such flags vary importantly from cell to cell; and while those of eggs complement those of sperm (perhaps in a well matched tug of war), other cells&#8217; marks may need to be overwritten to make a healthy zygote.</p>
<h2>Loss of rescuing mitochondria</h2>
<p>Early methods of mitochondrial rescue mixed cytoplasm from one egg into the cytoplasm of another, to add genetically hardier mitochondria to the zygote&#8217;s existing stock. As cells grow and divide, so do their mitochondria, some of which go into each descendant cell. So a given cell line that starts with both healthy and unhealthy mitochondria might slowly lose the healthy ones &#8212; whether by chance, or by mechanisms that purge newly arrived mitochondria (<em>e.g.</em>, those from sperm) that are replicating out-of-sync with others already there. And such loss of the healthy mitochondria could risk resurgence of the disease that mitochondrial rescue aimed to avoid.</p>
<p>The new methods that may win American and British approval, however, don&#8217;t mix cytoplasm, but instead move <em>nuclei</em> (bags of long chromosomes) into cytoplasm containing only healthy mitochondria, so original unhealthy aren&#8217;t there to resurge in the developing child. As such, the risk of losing the new, healthy mitochondria is minimized.</p>
<p>[7] This would, of course, be a kind of state-enforced eugenics.</p>
<p>[8] Legal arguments about the health of kids who might not otherwise have be born are apparently <a href="https://blogs.law.harvard.edu/billofhealth/2014/02/24/fda-mitochondrial-manipulation-three-parent-children-and-the-ny-times/">nuanced</a>, however.</p>
]]></content:encoded>
		<wfw:commentRss>/2014/04/06/threesomics/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Three small steps toward genomically sensible healthcare</title>
	<link>/2013/08/26/three-small-steps-toward-genomically-sensible-healthcare/</link>
	<comments>/2013/08/26/three-small-steps-toward-genomically-sensible-healthcare/#respond</comments>
	<pubDate>Mon, 26 Aug 2013 08:44:30 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genetics, evolution, and policy]]></category>

	<guid isPermaLink="false">/?p=55</guid>
	<description><![CDATA[Sailing a close reach, San Francisco Bay. (Image copyright Nathaniel Pearson) A talk at the Clinical Genome Conference resonated with some folks, who suggested sharing...]]></description>
		<content:encoded><![CDATA[<p><img src="/wp-content/uploads/2013/08/Sailing-1024x625.jpg" alt="Sailing a close reach, San Francisco Bay. (Image copyright Nathaniel Pearson)" /></p>
<p>Sailing a close reach, San Francisco Bay. (Image copyright Nathaniel Pearson)</p>
<p><a href="http://www.slideshare.net/NathanielPearson/pearsontcgc2013">A talk</a> at <a href="http://www.clinicalgenomeconference.com/">the Clinical Genome Conference</a> resonated with some folks, who suggested sharing it. Crucially, that crowd included doctors, who have much to both teach and learn in the brave new world of genomic medicine. With them on hand, the day&#8217;s session loosely echoed a <a href="http://en.wikipedia.org/wiki/Grand_rounds">grand rounds</a>, where the case was, soberingly, the tall order of making genomes widely useful in healthcare.</p>
<p>In such circles, a genomicist like me is a narrow specialist. Bigger speakers &#8212; general practitioners, so to speak &#8212; were lined up to cover the chronic, integrative needs on the <a href="http://www.sciencenews.org/view/generic/id/346343/description/Buzzword_bingo">conference bingo</a> card: <em>convening stakeholders</em>; <em>establishing standards for reporting and payment</em>; <em>managing big data</em>&#8230;a wordsquall that looms over our field, <a href="http://quoteinvestigator.com/2010/04/23/everybody-talks-about-the-weather/">easy to discuss</a> but hard to fix.</p>
<p>So rather than tackle such broad challenges, my talk stayed bite-size. Building from insights on genome structure, function, and variation, it urged three small but concrete ways to help put genome-informed healthcare on firmer footing.</p>
<ul>
<li>Use different reference genomes to align a person&#8217;s raw data (pick reference(s) most like her/him) versus store her/his finished genome (as clear or potential differences from the <em>human ancestral reference</em>).</li>
<li>Clinically classify <em>genotypes</em>, not variants.</li>
<li>Filter a genome against other <em>individuated genomes</em>, not allele frequency tables.</li>
</ul>
<p>Though these ideas aren&#8217;t new, they would break convention &#8212; so need justifying. But even if you skip the explanations that follow (starting with this post), know that the proposals reflect long thought on how current convention, rooted in sparse data, will ultimately fail for millions of whole human genomes. Thus consider them early course tweaks that can save bigger tacks later, en route to genomically informed healthcare for all of us.</p>
<h2>Small step I: The right reference genome(s)</h2>
<p>A reference genome &#8212; we&#8217;ll just say <em>reference</em> &#8212; is a long string of letters used as a common template for comparing the genomes of closely related organisms, such as people. As an archetype, a reference often shortens and simplifies real genomes,[1] to help <em>read</em>, <em>write</em>, or <em>interpret</em> them.</p>
<p>In teasing apart these tasks, note that today we use the same human reference for all three&#8230;and that it&#8217;s right for none of them. Below we&#8217;ll see why, and what we should do about it. But if you&#8217;re rushed, here&#8217;s the gist:</p>
<p><em>The current single reference is arbitrary and ethnocentric; inevitably misaligns most people&#8217;s raw data; and is poor for writing and interpreting genomes afterward, because it includes rare and risky variants, and muddles summary insights on data quality and evolution.</em></p>
<p>An alternative made of just common or putatively healthy variants would still be unreliable for aligning raw data, and as a foil for writing and interpreting genomes.</p>
<p>Instead, we should read your genome by aligning raw data to references most like you (we can usually guess which). We should then write all our genomes against the human ancestral reference &#8212; a solution that&#8217;s ethnically neutral, directly informative on data quality and evolution, and stabler than alternatives.</p>
<p>And we should give up on using any reference to proxy an idealized healthy genome. As later posts will detail, reliable health insight will instead require comparing your genome to the individuated whole genomes of many other people who, like each of us, get some diseases and not others.</p>
<p>Ok, now let&#8217;s walk through those reference tasks in detail, to better understand why we must do them differently.</p>
<h2>Read</h2>
<p>To read your genome &#8212; that is, to make out the long eye chart of letters that form it &#8212; a modern sequencer streams zillions of DNA snippets, each copying a chromosome tract roughly at random. By comparing each snippet to a good reference, a computer can find where it best fits, much as we match jigsaw puzzle pieces to the picture on the box. As snippets pile up, the computer surveys what DNA letter(s) amass over each spot, to guess what letter(s) your chromosomes carry there.[2] Conventionally, we&#8217;ve taken a one-size-fits-all approach to this task of <em>aligning</em> snippets, using the same reference, called <em>Hg#</em> (where today # = <a href="http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/">19</a>), to scaffold everyone&#8217;s genomes.[3] But Hg# wasn&#8217;t carved in stone. Instead, it&#8217;s quilted from <a href="http://seqanswers.com/forums/archive/index.php/t-22278.html">several real people</a>&#8216;s genomes that were read by costly, reference-free methods. And the haphazardly picked people who contributed to it have their own ancestry, which gives Hg# their genetic quirks.</p>
<p>As a result, some human genomes are more like Hg# than others. And if my genome resembles it more than yours does, my snippets will, on average, align more reliably. Conversely, because <a href="/ne/">big populations tend to be genetically diverse</a>, Hg# &#8212; like <em>any</em> single option &#8212; inevitably misaligns raw data from <em>most</em> people&#8217;s genomes, in ways both big (mutual gaps and rearrangements wreak havoc) and small (clustered small differences leave good snippets unaligned).</p>
<p>In the end, this means that <em>we can best read your genome today by first aligning to the available genome(s) most like it.</em>[4] Happily, <a href="http://en.wikipedia.org/wiki/SNP_array">skimming</a> your genome &#8212; or even just looking at you &#8212; strongly hints whose genome(s) might work best.[5] How well we can play reference sommelier depends on what options are on hand (more and more, starting with <a href="http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1002280">synthetic references</a> that proxy what&#8217;s common in a particular part of the world), and how saliently <em>mixed</em> your recent ancestry is. But if needed we can try <em>multiple</em> references, and see which work best for which snippets.</p>
<p>And that raises two deeper points. First, for some genome segments, such as a <a href="http://en.wikipedia.org/wiki/Human_leukocyte_antigen">stunningly diverse and health-relevant stretch of chromosome 6</a>, it&#8217;s hard to predict what your genome looks like <em>regardless</em> of where your forebears came from. For such segments, it makes sense to <em>always</em> align your snippets to many reference options.[6] Doing so takes a few more electrons, but usefully sharpens the resulting picture of your genome.</p>
<p>Second, aligning your snippets to even one whole <em>real</em> genome would itself be like aligning them to <em>two</em> versions of a conventional reference (with its one copy of each chromosome that&#8217;s paired in real genomes). Smartly, that could fully leverage new algorithms that track <em>everywhere</em> a snippet decently fits during alignment, rather than just picking one spot (often by tossup). And that, in turn, would let us read your genome more finely, without &#8212; yet &#8212; needing the compact simplicity of a conventional reference like Hg#.</p>
<p>Which brings us to the next use of a reference&#8230;</p>
<h2>Write</h2>
<p>After we read your genome in detail, a reference helps <em>write</em> it. Namely, because copies of a given human chromosome are all grossly alike, we can thriftily store yours by just noting where one or both mismatch a simple (single-copy) reference, or were read too poorly to tell.</p>
<p>Everywhere else &#8212; typically, >95% of the currently sequenceable parts of human chromosomes &#8212; we can assume that your copies match that reference. And because many of your poorly read sites will themselves clump in compressible tracts, we can shrink your genome >>20-fold in the end. That saves memory, of course, but also helps us query it &#8212; most usefully, by comparing your DNA (plus your phenotypes, ideally) to others&#8217;.</p>
<p>But there&#8217;s a catch. Because mutation anywhere on a chromosome can make one copy of it <em>longer</em> than another, genomes can best be compared if stored as differences from the same reference, so their mapping coordinates match. That way, like sailors agreeing to <a href="http://en.wikipedia.org/wiki/Prime_meridian">track longitude from Greenwich</a>, we can neatly record findings like <em>&#8216;One of your chromosome 7′s shows five more bases (ACGTA) than mine at reference site 1000; but one of mine shows three fewer bases at reference sites 2000-2002</em>&#8216;&#8230;</p>
<p>Note the dilemma here: to read genomes, we should align their snippets to <em>various</em> most-appropriate real reference(s); but to compare them, we should write them as differences from the <em>same</em> simple reference.[7] Bottom line, we need task-specific references.</p>
<p>But that still means picking one best reference for writing genomes. Given that so much work has gone into Hg#, we might ask whether <em>it&#8217;s</em> the right one. Which leads us to the third use of references&#8230;</p>
<h2>Interpret</h2>
<p>After shrinking your genome to a list of differences from a reference, we&#8217;d like to understand that list &#8212; what it says about how sequencing went and, more importantly, about you. We might even hope to use the reference to proxy a <em>healthy</em> genome, so that anything worrisome in your genome stands out from it.</p>
<p>Alas Hg# makes a poor interpretive foil for real genome data, starting with quality control: because Hg# comes from a few modern people, it&#8217;s poor not just for aligning, but also for writing, where it can conflate statistical signatures of lab-bench problems (sample contamination, chemistry failure, &amp;c.) with those of ancestry. QC that first compares <em>heterozygosity</em> of particular genome segments, rather than just counting reference sites called with any mismatch, will help there (an issue for another day&#8230;), but the problems with the current reference go deeper.</p>
<p>In particular, Hg# also includes many variants already <a href="http://www.ncbi.nlm.nih.gov/pubmed/21121051">implicated in diseases</a> &#8212; which means it won&#8217;t always flag your own worrisome DNA spellings[8] , and that it troublesomely differs from some <a href="http://www.lrg-sequence.org/">single-gene references</a> familiar to clinical geneticists. Moreover, Hg# includes many other variants that, while not yet well studied, are <a href="/rare-variants-and-health/">suspiciously rare</a> enough to be harmful too.</p>
<p>Given those shortcomings, many have suggested replacing Hg#&#8217;s rare and/or known risky variants with common and/or healthy alternatives, ostensibly yielding a new reference that reliably proxies a healthy, normal genome.</p>
<p>Alas, that won&#8217;t work, for two reasons. <em>What&#8217;s common varies. And what&#8217;s healthy depends.</em></p>
<h2>Informative beats (un)healthy</h2>
<p>At first glance, one of your DNA spelling variants may be rare enough on earth overall to intrigue us &#8212; but turn out to be boringly common among millions of mostly healthy people in some small patch of the planet. More profoundly, the commonest variant at a genomic site today or in five years may not be the commonest one next year or in ten years. That&#8217;s evolution &#8212; and it means that a common-only reference is inherently unstable.</p>
<p>On the health side, meanwhile, many variants aren&#8217;t simply good or bad. Their effects depend on what how many copies you have (0, 1, or 2), what disease we ask about, and what <em>other</em> variants lurk in your genome.</p>
<p>You may know a few such twists already. <em>One or two copies of T <a href="http://genome.ucsc.edu/cgi-bin/hgTracks?position=chr11:5247982-5248482&amp;hgsid=345050099&amp;snp137Common=pack&amp;hgFind.matches=rs334,">here</a> help avoid malaria and high cholesterol &#8212; but two copies leave you with crippling anemia. One copy of A over <a href="http://genome.ucsc.edu/cgi-bin/hgTracks?hgHubConnect.destUrl=..%2Fcgi-bin%2FhgTracks&amp;clade=mammal&amp;org=Human&amp;db=hg19&amp;position=chr17%3A41243941&amp;hgt.positionInput=chr17%3A41243941&amp;hgt.suggestTrack=knownGene&amp;Submit=submit&amp;hgsid=345051025">there</a> can drive breast cancer, but mainly if you also lack a working copy of the <a href="http://en.wikipedia.org/wiki/SRY">SRY</a> gene (which, on the flipside, helps you avoid testicular cancer, among other diseases&#8230;).</em> And so forth.</p>
<p>Data from millions of us will unfurl more astounding complexity, where variants throughout your genome &#8212; some inevitably present in any reference we use &#8212; interact in surprising ways with each other, and with habits and other factors, to favor some diseases and disfavor others.[9] Other posts will further explore how this hard truth should alter our approach to genomic healthcare. Here, it simply dooms any hope of using any reference to reliably proxy what&#8217;s healthy.</p>
<p>And more deeply, using a reference like Hg# as an interpretive yardstick also obscures how genomes change and, by extension, how various kinds of changes tend to affect health in the first place. Hg# can&#8217;t, for example, tell us whether a so-called <em>deletion</em> in your genome (where it&#8217;s missing a tract found in Hg#) really reflects a mutation that deleted bases in you or your forebear, or instead reflects an <em>insertion</em> of bases in someone who contributed to Hg#.</p>
<p>As such, because a given letter in a reference like Hg# could itself reflect a past mutation, writing <em>everyone&#8217;s</em> genomes as differences from Hg# makes statistical questions like <em>&#8216;How often does the snippet CG mutate to TG? And how well does that TG survive, over generations, if it changed a protein&#8217;s arginine to cysteine?&#8217;</em> trickier than they should be.</p>
<p>Such questions matter. They can unlock basic physiology (<em>How do mutations happen? Why do tumors correct them so poorly?</em>); hint how a new variant may affect health (<em>Does changing active-site arginine to cysteine often make an enzyme fail?</em>); and clarify how variants <em>interact</em> with each other, and with habits, to cause disease (<em>Why do some genetic variants, like <a href="http://snpedia.com/index.php/ApoE-%CE%B54">APOE-ε4</a>, make us sick but leave chimpanzees healthy?</em>).</p>
<p>Those big questions require the big data inside us. Even if no more than a handful of your DNA spellings alter your own healthcare, the rest of them, pooled with similar data from all of us, can shed light on many diseases to greatly refine care for our grandkids.</p>
<p>But using a conventional reference like Hg# needlessly hinders that effort. So while we must abandon the idea of any reference reliably proxying a healthy genome, can we at least find a sensible reference to write and compare the coming flood of genomes, to catalyze those deeper insights?</p>
<h2>An ancestral reference</h2>
<p>We can. The sensible yardstick for writing your genome is the <em>human ancestral reference</em> (<em>HAR</em>) &#8212; that is, a single-copy genome comprising, at each chromosomal site, the DNA letter carried by the last common ancestor of all people for that site.</p>
<p>In picturing the HAR (which <a href="https//twitter.com/suganthibala">Suganthi Balasubramanian</a> and colleagues have already <a href="http://genesdev.cshlp.org/content/25/1/1.long">described here)</a>[10] , note something very important: two genomic sites, even on the same chromosome, can trace to <em>different</em> last common ancestors. That&#8217;s because, when eggs and sperm are made, chromosomes pair up, swap segments, and move into different cells. Each copy of a chromosome thus quilts together pieces of earlier copies; so everyone&#8217;s last common ancestor for site 1000 may not be our last common ancestor for site 1001 (they may have even lived eons apart). Which also means it&#8217;s implausible that any person ever carried the whole HAR.[11] Among reference options for writing and comparing our genomes, the HAR uniquely combines several appealing features:</p>
<ul>
<li><em>It&#8217;s neutral.</em> As noted, no one ever carried the whole HAR. And because the mutations that distinguish our genomes from it have struck roughly randomly among our ancestors, your genome resembles it about as much as mine does.[12]
<p>In this important sense, the HAR belongs to none of us, and to all of us. Being roughly equidistant from everyone, it offers a uniform, non-ethnocentric baseline for assessing sequencing quality, and for reporting what&#8217;s genetically distinctive about you.</p>
</li>
<li>
<p><em>It&#8217;s stable.</em> The HAR actually looks a lot like a common-variants-only reference, because nearly all ancestral variants are common. But while a common-only reference would in principle need many edits each year to stay perfectly accurate, the HAR would need just a few (as atypically rare ancestral variants are newly found or, occasionally, learned to have gone extinct).[13]</p>
<p>Such editing isn&#8217;t urgent, because few variants with allele frequency near 50% are functionally intriguing enough, or surveyed precisely enough in the population, to day-trade anyway. But that just makes it even smarter to build a reference on the stable, reliably inferrable, and meaningful criterion that a variant be ancestral, rather than worry whether its allele frequency fell to 49.9%. That way, we get summary insights even from otherwise boring variants &#8212; and a low-maintenance reference to boot.</p>
</li>
<li>
<p><em>It&#8217;s compact but comprehensive.</em> Like conventional references, the HAR is a simple single-copy (<em>haploid</em>) genome. Real genomes, compressed against it, would yield files consistently intermediate in size between the biggest and smallest files compressed against Hg#.[14]</p>
<p>Nonetheless, because new chunks of DNA are usually copied from chunks elsewhere in the same genome, the HAR includes source DNA for nearly all chunks of real human genomes (missing only those recently copied from viruses or bacteria, or other oddities). Other reference options tend to be less comprehensive on these counts, which poses an ongoing dilemma of when to add a segmental copy (to make them more thorough), versus omit it (to keep them compact).[15]</p>
<p>That dilemma would still hold, but the HAR offers a framework for handling extra segments that we choose to include in the <em>extended</em> HAR that <a href="http://genesdev.cshlp.org/content/25/1/1.long">Subramanian <em>et al.</em> proposed</a>. For a newly arisen extra segment that some but not all people have, variation <em>among</em> such copies could in turn be mapped to common coordinates in the inferred earliest (nearest to universally ancestral) version of the new copy.</p>
</li>
<li>
<p><em>It&#8217;s directly informative.</em> Most importantly, the HAR is the only reference option that directly shows how human genomes change. As a foil for writing all our genomes, it would thus most quickly reveal summary patterns of change that in turn shed light on basic biology and health.As a concrete example, if shortening a particular bend shared by a particular family of proteins makes people sick, but lengthening it &#8212; or shortening another bend &#8212; leaves people healthy, the HAR would let clinical geneticists reliably spot this trend faster than other references would.</p>
</li>
</ul>
<p>The benefits of an ancestral reference for making sense of genomes, both individually and together, have long been starkly clear for geneticists studying the first fully sequenced human chromosome: the mitochondrial genome (mtDNA).</p>
<p>Starting in 1981, we used the <a href="http://www.ncbi.nlm.nih.gov/pubmed/7219534">first sequence of a person&#8217;s mtDNA</a> as a reference. That sequence forms a leaf on the <a href="http://www.phylotree.org/tree/main.htm">simple evolutionary tree</a> that binds all our mtDNA versions. And because each of us gets only our mom&#8217;s version of this short but gene-rich chromosome, with no backup from dad, that tree&#8217;s branches are key foci of health research.</p>
<p>But using a modern person&#8217;s mtDNA as a reference meant treating a leaf as if it were the treetrunk. This everted our view of the tree, prompting <a href="http://www.dailymotion.com/video/xerwsh_carl-sagan-videos-epicycles-of-ptol_tech">epicycle</a>-like contortions to figure out where your leaf was, and how your branch may or may not have mutated in telling ways.</p>
<p>In 2012, researchers cut that gordian knot, proposing the <a href="http://www.mtdnacommunity.org/">human ancestral mtDNA</a> as a reference for writing real genomes. That new reference lets you easily a) find your mtDNA leaf, and b) see how DNA has changed throughout the tree, to better understand key biological processes.</p>
<p>Having learned the hard way with mtDNA, we needn&#8217;t wait 31 years for our other chromosomes. In the end, by using multiple references to align raw data, and adopting the HAR to write and compare our finished genomes, we can best read, write, and learn from the millions of human genomes soon to be sequenced.</p>
<h2>Getting smarter with references</h2>
<p>So where are we, as a community, on human reference genomes?</p>
<p>There&#8217;s modest reason to hope. Researchers have begun to show how much better we might read genomes by <a href="http://www.plosgenetics.org/article/info:doi%2F10.1371%2Fjournal.pgen.1002280">aligning snippets to similar reference(s)</a>; that an <a href="http://genesdev.cshlp.org/content/25/1/1.long">ancestral reference helps</a> compare genomes <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3322232/">more easily and informatively</a>; that <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmid/21121051/">Hg# doesn&#8217;t proxy a healthy genome</a>; and that <a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3254080/">no alternative would reliably do so</a> either.</p>
<p>On the practical side, we&#8217;re accumulating diverse, ever better sequenced human genomes that can serve well as alignment references (and, as a bonus, help <a href="http://www.nist.gov/mml/bbd/biomolecular/genome_in_a_bottle_consortium.cfm">benchmark new sequencing methods</a>). And we&#8217;re getting better genomes from elsewhere in the great ape family tree, to refine the HAR.</p>
<p>Moreover, today&#8217;s <em>de facto</em> standard, Hg#, continues to improve via thoughtful work by <a href="http://infocus.nlm.nih.gov/2012/08/meet-ncbis-deanna-church-genom.html">Deanna Church</a>&#8216;s team and <a href="http://www.ncbi.nlm.nih.gov/pubmed/23932108">others</a>. Beyond fixing errors and filling in previously missing segments, the pending Hg20 version will include <em>multiple</em> versions of more segments, in part to better align raw data.</p>
<p>That&#8217;s a sensible stopgap, until more folks start picking from multiple alignment references from the start. But adding alternate versions of more segments to Hg# requires ongoing arbitrary choices, slows the task of writing finished genomes, and tends to statistically weaken comparisons of many genomes. The latter jobs are really better served by writing genomes against the HAR.</p>
<p>Communal habits like using Hg# for all human reference needs are hard to break &#8212; even for open-minded scientists (and maybe moreso in famously stubborn medicine). But given the clear flaws in our current approach to reference genomes, it&#8217;s likely better to break those bad habits now than let them entrench further, as we start sequencing patients&#8217; genomes by the thousands (and more).</p>
<p>Making all those genomes useful in healthcare, for us and future generations, will mean reading them well; writing them efficiently; and, as coming posts will explore further, interpreting them wisely.</p>
<p>All these goals rest on the bedrock of reference genomes. Let&#8217;s get them right.</p>
<p>[^l] Today&#8217;s ~2.9 billion-letter <a href="http://genome.ucsc.edu/cgi-bin/hgTracks">human reference</a>, for example, comprises just one version of each of the grossly distinct-looking molecules (chromosomes 1-22, X, Y, and M) in the >6.5 billion-letter genome of a man&#8217;s skin cell. That cell&#8217;s genome comprises <em>two</em> copies of most such chromosomes &#8212; and those copies, in turn, differ in chemical makeup (base sequence), and include tracts that have never been seen (or successfully sequenced), so are simply missing from the reference.</p>
<p>[^2] Importantly, many snippets from your genome differ from even their best-matching parts of the puzzlebox picture (otherwise, why bother sequencing?). But the reference template still helps piece them together faster than we otherwise could. And by piling <em>many</em> snippets over each site, we can tune out errors from cooking finicky chemicals under tiny image sensors &#8212; a bit like how astronomers, at the other end of the spatial scale, distinguish lasting light sources from noise by overlaying many pictures of the same part of the sky.</p>
<p>[^3] While researchers colloquially use the <em>Hg</em> prefix, this technically denotes the version stored at the University of California Santa Cruz&#8217;s popular <a href="http://genome.ucsc.edu/">genome data portal</a>; the current reference&#8217;s proper name is <em>GRCh##.p__, where ## (currently 37) is a _major assembly release</em> number higher than the # in Hg#, and _ is a <em>patch release</em> number.</p>
<p>[^4] That point was moot in 2003, when we had to use the hardwon sequence that became the current reference. But since then, we&#8217;re bootstrapping our way to good sequences of <em>many</em> human genomes from around the world &#8212; a pool that we should tap to better align newly sequenced genomes, as some folks have already shown.</p>
<p>[^5] Ideally, we&#8217;d use parents&#8217; genomes to align those of their kids&#8230;but when sequencing is common enough to make that practical, sequencers will likely make longer snippets that are easier to piece together from the start anyway, even without aligning to a reference.</p>
<p>[^6] Helpfully, Hg# itself includes several options for some such segments &#8212; and those who built and refine it plan to add more.</p>
<p>[^7] Note that even though we write them as differences from a simple reference, which has just one copy of each chromosome, we can still readily encode which spellings go <em>together</em> on each copy of your chromosomes (if our sequencing method was good enough to tell in the first place).</p>
<p>[^8] Especially if whoever compressed your genome didn&#8217;t bother noting where your genome was too poorly sequenced to know what it carries &#8212; a corner that geneticists too often cut.</p>
<p>[^9] Such insights stand to turn much of the noise that we currently sweep under the rug of <em>partial penetrance</em> into far better understood signal &#8212; think, for example, about how genetic insight turned the apparent random noise of why a baby was born female or male into causal signal tracing largely to the sex chromosomes.</p>
<p>[^10] For the remaining sites, we can&#8217;t reliably guess what variant our last common ancestor carried, because the state of variation we see among our copies extends to other great apes, suggesting that such variation has either arisen twice, or lasted too long to reliably unravel. In extreme cases, like the sex chromosomes, such lasting variation is already enshrined in the current reference (Hg# has one X sequence and one Y sequence, despite the fact that not everyone has the latter).</p>
<p>[^11] Even the last common ancestors who contributed to the HAR had variants in their own genomes that aren&#8217;t in it.</p>
<p>[^12] Planetwide, we have no idea whose genome happens to differ from it most, though that person &#8212; ironically, in some sense the most evolved (geneticists would say <em>derived</em>) of us &#8212; is almost certainly very sick, thanks to gross genetic changes&#8230;</p>
<p>[^13] Many thanks to <a href="http://gcbias.org/">Graham Coop</a> and <a href="http://www.genetics.wustl.edu/jflab/">Justin Fay</a> for helping think through the relevant numbers here.</p>
<p>[^14] Average compression is the main measure that could instead be optimized by a common-only reference. But the HAR has several substantive advantages over that less stable and informative option.</p>
<p>[^15] Note, btw, that this question matters most if we&#8217;re using a reference to align snippets &#8212; which we&#8217;re not proposing here. But we do need to map each of the alignment references themselves to the writing/comparing reference, which is where it helps to make sure the latter includes source DNA for the segments that those alignment references may have extra or fewer copies of.</p>
]]></content:encoded>
		<wfw:commentRss>/2013/08/26/three-small-steps-toward-genomically-sensible-healthcare/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Harmful by any other name: On clinical variant classification</title>
	<link>/2013/05/22/harmful-by-any-other-name-on-clinical-variant-classification/</link>
	<comments>/2013/05/22/harmful-by-any-other-name-on-clinical-variant-classification/#respond</comments>
	<pubDate>Wed, 22 May 2013 06:42:30 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genomes and health]]></category>

	<guid isPermaLink="false">/?p=67</guid>
	<description><![CDATA[In Phoenix this week, clinical geneticists have gathered at ACMG to catch up on health-relevant genomic findings and tools, and decide how to best put...]]></description>
		<content:encoded><![CDATA[<p>In Phoenix this week, clinical geneticists have gathered at <a href="http://www.acmgmeeting.net/acmg2013/public/enter.aspx">ACMG</a> to catch up on health-relevant genomic findings and tools, and decide how to best put them into broad practice. Tonight, in particular, features a workshop on how to classify DNA spelling variants, and report them to patients and caregivers. Chief among questions at hand will be what to <em>call</em> such variants.</p>
<p>Led by the ever-thoughtful <a href="http://www.bizjournals.com/boston/stories/2010/10/11/focus38.html">Heidi Rehm</a>, the workshop is a great chance to define a sensible set of classification bins that best convey how each genetic variant likely affects the health of a person who might carry it.</p>
<p>With an eye to that question, here&#8217;s the most widely used binning scheme, put forth by <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=21681106">Kearney <em>et al.</em></a>[1]:</p>
<ul>
<li>Pathogenic</li>
<li>Unknown significance, Likely pathogenic</li>
<li>Unknown significance</li>
<li>Unknown significance, Likely benign</li>
<li>Benign</li>
</ul>
<p>And here, with some explanation to follow below, is an alternative to kick around:</p>
<ul>
<li>Harmful</li>
<li>Likely harmful</li>
<li>Not yet interpretable</li>
<li>Likely harmless</li>
<li>Harmless
<ul>
<li>Family-relevant</li>
<li>Treatment-relevant</li>
</ul>
</li>
</ul>
<p>In weighing these two schemes, first note that Kearney&#8217;s thoughtfully builds on a legacy that&#8217;s deeply familiar to many clinical geneticists &#8212; and has proved a good, if imperfect, rubric for current use. But as we slowly integrate genomic insights into healthcare for ever more people, from birth to old age, Kearney&#8217;s shortcomings may limit its shelf life. Let&#8217;s review.</p>
<h2>What the Kearney scheme gets right</h2>
<p><em>It&#8217;s sensibly simple.</em> Importantly, Kearney (the first scheme above) sorts variants by our best guesses about how they affect health &#8212; and uses a plain word (<em>likely</em>) to neatly distinguish weak guesses from strong ones, without dickering about likelihoods of likelihoods. No arbitrary hair-splitting.</p>
<p><em>It&#8217;s realistically fluid.</em> By making uncertainty explicit, Kearney accomodates changing knowledge. A variant understood poorly today, but well tomorrow, can just be reclassified from the cautiously neutral middle of the rubric toward one of its poles &#8212; or back again.</p>
<p><em>It&#8217;s accurate.</em> Kearney implicitly uses the generalizable term <em>variant</em>, not alternatives like <em>mutation</em> and <em><a href="/concepts-genetics-jargon/polymorphism/">polymorphism</a></em>, whose usages have drifted in misleading ways. In the long run, this can help people understand their genomes accurately &#8212; more on that another time.</p>
<h2>What the Kearney scheme gets wrong</h2>
<p><em>It calls carrier variants pathogenic.</em> Some variants &#8212; <em>dominant</em> ones &#8212; cause disease if found on either of a person&#8217;s copies of a chromosome. But others &#8212; mostly <em>recessive</em> &#8212; do harm only if found on <em>each</em> of that person&#8217;s copies, or along with another variant elsewhere in the genome. Kearney lumps all such variants together, so a man with one copy of a dominant variant, one copy of an autosomal recessive variant, one copy of an X-linked recessive variant, and two copies of an ovarian cancer-causing variant, will misleadingly see all four identically called <em>pathogenic</em> in his report. This problem reflects how such schemes simplistically focus on <em>variants</em>, instead of <em>genotypes</em>. But, as we&#8217;ll see, they could nonetheless clarify which worrisome variants will or won&#8217;t make a given person sick. Moreover, distinguishing such variants can help us know which to watch for in other family members (especially future children, who might get copies from both parents, or who might crucially differ in sex from the parent who gave them a particular variant).</p>
<p><em>It says nothing about drug (or other treatment) response.</em> Beyond calling predictably harmless carrier variants <em>pathogenic,</em> Kearney&#8217;s scheme ignores variants that predict response to drugs and other disease treatments. Notably, such variants are, for now, among the most informative variants in our genomes &#8212; especially for fairly healthy adults (that is, those of us not <em>urgently</em> scanning our genomes for key insight into disease). As is, Kearney would thus glaringly omit key insight from a typical whole-genome report.</p>
<p><em>It&#8217;s unclear.</em> Like much medical jargon (see discussion below), Kearney uses fancy, euphemistic words from Greek and Latin (<em>pathogenic</em> = &#8216;sick-making&#8217;, <em>benign</em> = &#8216;good&#8217;) instead of plainer words understood by more people[3]. Given the bully pulpit that ACMG has at the dawn of genomic medicine, the scheme that it picks will likely shape how people learn about their health for years to come. As such, the jargon-versus-plain-English question is key: Will genome reports coddle <em>doctors</em> by sticking with the latinate jargon they love, or will we use plainer synonyms that <em>patients</em> too understand?</p>
<p><em>It&#8217;s awkward.</em> In the Kearney-inspired parlance of clinical geneticists, the ungainly phrase <em>Variant of Unknown Significance</em> has long stuck out like a Thumb of Unrelenting Soreness on a <a href="http://www.urbandictionary.com/define.php?term=R.O.U.S.">Rodent of Unusual Size</a>. Unlike the other bin names, <em>VUS</em> isn&#8217;t an adjective. Meanwhile, <em>pathogenic</em> and <em>benign</em> are odd antonyms, as the former may sound like it involves germs, and the latter more often opposes <em>malignant</em>, in describing tumors. Such inconsistency &#8212; and the whiffs of germ and cancer talk &#8212; may not help patients understand easily.</p>
<h2>An alternative</h2>
<p>With those shortcomings in mind, let&#8217;s review the newly proposed alternative scheme. While closely resembling Kearney, it arguably refines it in several ways.</p>
<p>First, by using plain words like <em>harmful</em> and <em>harmless</em>, it would be immediately clear to many layfolk, and avoid patronizing euphemism. As such, a fresh step toward empowering patients in the coming era of genomically informed healthcare.</p>
<p>Second, the proposed scheme comprises only adjectives &#8212; mostly short ones &#8212; with poles defined by simple <em>-ful</em> and <em>-less</em> antonyms[4]. The adjective phrase <em>not yet interpretable</em>, while still a bit awkward, plainly conveys both neutrality and openness to change.</p>
<p>Third, it highlights both carrier variants (<em>family-relevant</em>) and <em>treatment-relevant</em> variants in plain ways, accessible to both doctor and patient, that don&#8217;t unduly alarm or reassure. Note that while I&#8217;ve tentatively filed both new classes under <em>harmless</em>, based on their effects for the patient at hand, they don&#8217;t fit neatly there. Note too, that many drug response variants, in particular, may even be <em>helpful –</em> a category generally lumped in under <em>benign/harmless</em> in all these schemes.</p>
<p>At tonight&#8217;s workshop, I may float some of the ideas proposed here. While response may well be lukewarm at best, given the momentum that Kearney-like clinical genetics nomenclature has already gained, there may be no better time to speak up on the matter.</p>
<p>[1] The scheme was first proposed for variants involving long repetitive chunks of the genome, but has now been adopted more broadly.</p>
<p>[2] It&#8217;s worth asking, however, whether those two terms are too hard to uniquely abbreviate (<em>HF</em>? <em>HL</em>?), or would be readily confused in typing, reading, or speaking. If so, could an even shorter term like <em>OK</em> could sub for <em>harmless</em>?</p>
<p>[3] This habit likely dates to when Latin was the key shared language of European scholars – letting healers in, say, England, Italy, and Poland easily share new discoveries with each other.</p>
<p>Today, of course, science&#8217;s <a href="http://en.wikipedia.org/wiki/Lingua_franca">lingua franca</a> is English (and tomorrow perhaps Mandarin&#8230;). But while English taps two big stocks of words for the same things – pithy Germanic (<em>shit, yearly</em>) and flowery Greco-latinate (<em>excrement, annually</em>) – doctors (like lawyers and us scientists) find that continuing to cloak their work in layers of Greco-latinate jargon does three handy things.</p>
<p>First, it discourages DIY (or other) alternatives to their services. (<em>Ah, I have a contusion that may become a hematoma? Wow, thanks, doc – and I thought it was just a bad bruise&#8230;</em>).</p>
<p>Second, it hides knowledge from others – sometimes rightly (eavesdroppers in a hospital lift), sometimes not (an adult patient who wants frank talk, not patronizing euphemism).</p>
<p>Third, it binds them (well, us scientists too) in clubby solidarity, perhaps safeguarding a sense of prestige (<em>As we learned in med school, the reeeal word for right pinky is digitus minimus manus dextra&#8230;</em>).</p>
]]></content:encoded>
		<wfw:commentRss>/2013/05/22/harmful-by-any-other-name-on-clinical-variant-classification/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>The Shock of the New: What we can say about HeLa&#8217;s novel variants</title>
	<link>/2013/04/01/the-shock-of-the-new-what-we-can-say-about-helas-novel-variants/</link>
	<comments>/2013/04/01/the-shock-of-the-new-what-we-can-say-about-helas-novel-variants/#respond</comments>
	<pubDate>Mon, 01 Apr 2013 15:38:09 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genetics, evolution, and policy]]></category>

	<guid isPermaLink="false">/?p=37</guid>
	<description><![CDATA[A human genome, remixed, and gone viral. In a nutshell, that&#8217;s the conditionally re-published genome of HeLa cells, which flourish in labs worldwide, but trace...]]></description>
		<content:encoded><![CDATA[<p>A human genome, remixed, and gone viral. In a nutshell, that&#8217;s the <a href="http://www.nature.com/news/deal-done-over-hela-cell-line-1.13511">conditionally re-published</a> genome of <a href="http://en.wikipedia.org/wiki/HeLa">HeLa</a> cells, which flourish in labs worldwide, but trace back seven decades to the unethically biopsied cervical tumor of American <a href="http://en.wikipedia.org/wiki/Henrietta_Lacks">Henrietta Lacks</a>.</p>
<p>Notably, HeLa&#8217;s genome offers vital glimpses of the woman whose life it stole. But as a posthumous portrait of Lacks, it&#8217;s at best a <a href="http://en.wikipedia.org/wiki/Cubism">cubist</a> one &#8212; her genomic likeness reduced to shards jumbled, mirrored, and spattered by decades of mutation. In time, though, it will prove to recognizably portray <em>her</em>, first in generically broad strokes, but eventually in more intimate ways that only she and her loved ones had known.</p>
<p>And that prospect sparked rancor in March, when the authors who first <a href="www.g3journal.org/content/early/2013/03/12/g3.113.005777.abstract">published</a> (and then withdrew, amid the hubbub) a HeLa genome patly <a href="http://phylogenomics.files.wordpress.com/2013/03/pr-diff.pdf">denied</a> that their data shed light on Lacks&#8217;s own <em>genome</em>, much less on who she was:</p>
<blockquote><p>
  [W]e cannot infer anything about Henrietta Lacks&#8217; genome, or of her descendants, from the data generated in this study [because] it is impossible to distinguish which parts of the genome sequenced here originate from Mrs. Lacks, her tumour, or laboratory adaptation.&#8217;
</p></blockquote>
<p>By this, they hoped to justify publishing a genome derived from one named person, without personal or family consent. That claim anticipated <a href="http://www.michaeleisen.org/blog/?p=1341">lively new discussion</a> of <a href="http://www.technologyreview.com/view/512966/the-dawn-of-genome-trolling/">genomic privacy</a> &#8212; but it was false, roughly like the finder of a rain-soaked wallet conveniently declaring the banknotes legible, but the IDs too wet to read.</p>
<p>Their own paper, after all, noted that HeLa shares nearly every noteworthy letter of its genome with other people (though their log-scaled bar plots downplayed this). And eventually, prodded by <a href="http://www.nytimes.com/2013/03/24/opinion/sunday/the-immortal-life-of-henrietta-lacks-the-sequel.html?src=me&amp;ref=general&amp;_r=1&amp;">other voices</a>, they conceded that we <em>can</em> learn and confirm some things about Lacks from HeLa&#8217;s DNA (or even <a href="http://www.genomesunzipped.org/2013/03/henrietta-lackss-genome-sequence-has-been-publicly-available-for-years.php">RNA</a>)[1] &#8212; but, they insisted, little if anything &#8216;new&#8217;.</p>
<p>And that&#8217;s truth&#8230;if not whole truth. For the authors apparently took <em>learning something</em> to mainly mean figuring out which of the 550 thousand or so <em>novel</em> (never before seen) variants they found had originally belonged to Lacks.[2] And yes, doing so without comparing HeLa&#8217;s genome directly to a non-HeLa genome from Lacks is indeed tough &#8212; at first glance, a genomic one-hand-clapping <a href="http://en.wikipedia.org/wiki/koan">koan</a>.</p>
<p>But even if identifying such variants really were the only route to learning something about Lacks, the authors ignored ways in which we <em>can</em> do so. Below, I&#8217;ll detail a few &#8212; which all boil down to thinking carefully about particular branches of the genetic family trees that link each segment of HeLa&#8217;s genome to the genomes of other cells and people.</p>
<p>Let&#8217;s start with novel variants that likely did <em>not</em> belong to Lacks.</p>
<h2>Novel variants that likely arose only in the HeLa cell lineage</h2>
<h3>Single-copy variants in duplicated haplotypes</h3>
<p>The HeLa genome is not easy reading. It&#8217;s basically a long, gibberish-spiked recipe for making tons of human cells. And if such a postmodern cookbook sounds riveting, you&#8217;ll be pleased to know that it&#8217;s written mostly in lawyerly triplicate.</p>
<p>In the decades after Lacks was born (perhaps in one big event, such as a faulty cell division), HeLa gained an extra copy of nearly every chromosome. And, though the new paper missed the next point, HeLa&#8217;s extensive <em><a href="http://en.wikipedia.org/wiki/Polyploid">triploidy</a></em> can help clarify which of its many distinctive variants arose by new mutation in the cell line, after Lacks was conceived (and perhaps after she died).</p>
<p>Basically, the duplication(s) that turned HeLa triploid effectively sprouted tiny new branches in the human genome&#8217;s family treetops, but <em>within</em> the HeLa genome itself. And some novel variants in HeLa can be confidently traced to those new branches, clarifying that they likely arose by mutation after Lacks was conceived.</p>
<p>Specifically, if a novel variant appears on just one of the three copies of a given chromosome in HeLa, <em>and the surrounding sequence is otherwise nearly identical to just one of the two other copies</em>, then the variant in question most likely arose by such new mutation. That is, Lacks likely wasn&#8217;t born with it. Similar logic can help us pick out likely new mutant variants in parts of the HeLa genome (such as long stretches of chromosomes 1, 5, and 11) that show even <em>more</em> than three copies.</p>
<p>Overall, to figure out which of the half-million or so heterozygous novel variants found in HeLa go into this bin, we&#8217;d need to systematically check which other variants they&#8217;re linked to on particular copies of particular chromosomes. With current lab methods, that&#8217;s hard &#8212; especially for novel variants, where we can&#8217;t turn to reference data from human populations &#8212; but feasible <strong>[Update: a new <a href="http://www.nature.com/nature/journal/v500/n7461/full/nature12064.html">paper</a> from <a href="http://www.gs.washington.edu/faculty/shendure.htm">Jay Shendure</a>&#8216;s group reports doing just that!]</strong>.</p>
<h3>Heterozygous mitochondrial variants</h3>
<p>Mitochondria are our cells&#8217; tiny furnaces. Each one houses a short, gene-crammed ring of DNA, attesting direct descent from a bacterium that, eons ago, slipped inside a bigger cell, to found <a href="http://en.wikipedia.org/wiki/Eukaryote">a line of ancestors</a> that we share mainly with plants, molds, and other animals.</p>
<p>Because all your mitochondria come from the few that your mother&#8217;s egg carried, they tend to be nearly identical within each cell, and throughout your body. That is, though their genomes do mutate (so can vary a bit from mitochondrion to mitochondrion), any resulting variation tends to wash out when we read a person&#8217;s DNA <em>en masse</em>.</p>
<p>As such, in a person&#8217;s mitochondria, we expect to find very few genomic sites &#8212; typically zero, in some people one &#8212; that look heterozygous (coming in two or more distinct flavors within a given genome) in the classic genetic sense. In fact, if we see more than one such site, we can guess fairly strongly that something has gone wrong either with sequencing itself (such as sample cross-contamination), or with the genome we&#8217;re looking at.</p>
<p>The HeLa researchers didn&#8217;t report how many of the novel mitochondrial variants, if any, appeared heterozygous in the HeLa genome. But if any did, it&#8217;s a good bet that most or all of them arose long after Lacks was born. And though this bin is likely very small, it&#8217;s one that can be fairly confidently assessed, in part by picking through raw sequence data more carefully; as such, it might tell us a <em>bit</em> about the point mutation rate in HeLa, relative to other tumor cell lines.</p>
<h3>Variants that don&#8217;t turn up in other HeLa lines</h3>
<p>This is the first big, obvious bin that will eventually subsume many of HeLa&#8217;s currently puzzling variants. Many variants that appear in the recently sequenced HeLa line will turn out not to appear in most or all other lines that we might eventually look at. While this can reflect <em>loss</em> of such variants, by deletion of segments of DNA in some HeLa lines, it more often will reflect <em>gain</em> of the variant in question in this particular line.</p>
<p>As such, fleshing out the genetic family tree of other HeLa lines will help clarify which such variants trace specifically to the branch that the new paper focuses solely on. Now, on to the other class of novel variants that interest us: those that likely belonged to Lacks from the start&#8230;</p>
<h2>Novel variants that Henrietta Lacks was likely conceived (and born) with</h2>
<h3>Novel ancestral variants</h3>
<p>In evolutionary parlance, an ancestral variant is, specifically, a variant carried by the last common ancestor of <em>everyone</em> in a population, for a given stretch of the genome, <em>before</em> any mutation there gave rise to a new variant that&#8217;s now found in some but not all individuals.</p>
<p>Most ancestral variants are still common among us, so were discovered long ago. But the haul of novel variants found in a given person may include the odd ancestral one that, til now, had never been hooked by researchers fishing in our gene pool.</p>
<p>Most such variants can be spotted easily, because they&#8217;re shared with many other mammals. Sometimes, such matches just reflect <em><a href="http://en.wikipedia.org/wiki/Convergent_evolution">homoplasy</a></em> – that is, mutation that happened to yield a variant already found in other organisms, perhaps at sites that tend to mutate a lot (such as Cs before Gs). But the commoner case &#8212; and the simpler guess, given how rarely mutation&#8217;s lightning strikes a typical site in the genome (and how rarer still it is for the mutation to happen to yield a particular variant seen elsewhere too) &#8212; is that a variant shared with most other mammals is really ancestral.</p>
<p>As such, among the novel variants called in HeLa, a few will confidently look ancestral &#8212; and most of these were, very likely, inherited by Lacks from her parents.</p>
<h3>Homozygous novel variants, outside LOH and/or cancer-implicated regions</h3>
<p>Whether ancestral or otherwise, novel variants tend to be rare &#8212; so rare that, by definition, they&#8217;d never been seen in a person before. As such, a given novel variant in your genome is very unlikely to also be carried by a randomly (er, carefully) chosen mate. And even if that person does carry a copy of the same very rare variant, there&#8217;s rarely more than a one in four chance that a child you&#8217;d have together will get two copies of it (one from each parent).</p>
<p>As such, nearly all novel variants found in your genome (or anyone&#8217;s) are <em>heterozygous</em> – that is, found on just one of your two copies of a given chromosome. Nonetheless, a smattering of novel variants may instead be homozygous, by the jackpot luck described above.</p>
<p>The HeLa genome reportedly harbors roughly 50 thousand homozygous novel variants &#8212; and that&#8217;s quite a lot, compared to most human genomes. Given that Lacks&#8217;s parents weren&#8217;t close relatives, I&#8217;d guess that many of these are in long stretches of the HeLa genome (such as most of chromosomes 6 and X) that look uniformly homozygous, likely due to <a href="http://en.wikipedia.org/wiki/Loss_of_heterozygosity">loss of heterozygosity</a>, where HeLa gained or lost copies of the given genome segment. Within these segments, and in genes that likely help govern HeLa&#8217;s growth, the origins of homozygous novel variants are hard to guess. Some may indeed have popped up by mutation in HeLa lineage, then become homozygous by secondary mutation. But others may have been in Lacks&#8217;s genome from the start.</p>
<p>But outside such regions, most homozygous variants found in HeLa &#8212; novel or otherwise &#8212; likely belonged to Lacks from the start. And we&#8217;ll eventually be able to confirm many of these guesses by looking at the next bin, below&#8230;</p>
<h3>Variants that turn up in other people</h3>
<p>This is the <em>other</em> big, obvious bin that will eventually subsume many of HeLa&#8217;s currently puzzling variants (the converse of the variants-that-don&#8217;t-turn-up-in-other-HeLa-lines bin described above). Of the 550-thousand-odd variants so far seen only in HeLa, many thousands will likely eventually be found in the genomes of living people whom we&#8217;ve yet to sequence. And most of these &#8212; especially if flanked by stretches of sequence that distinctively resemble the sequence flanking them in HeLa &#8212; will indeed be variants that Lacks was born with (rather than variants that arose in parallel by new mutation).</p>
<p>As such, it&#8217;s just a matter of time before we can trace many of the novel variants in HeLa to particular branches of the bigger human genetic family tree.</p>
<p>Importantly, some of these variants will, in turn, become functionally informative, once we&#8217;ve seen them enough times to see what kinds of traits people who carry them may distinctively share. Looking ahead, this is where HeLa&#8217;s genome will eventually show similarities to other genetic portraits of individuals, which in turn refine not just our picture of Lacks&#8217;s genome, but of what she was like as a person, inside and out.</p>
<h2>Further thoughts</h2>
<p>On first hearing that HeLa had been publicly sequenced, I smiled &#8212; a bit wistfully &#8212; and recalled stumping, in 2009, to do just that[3]. If you&#8217;re working at a genome interpretation company, and want to pick just one human(oid) genome to sequence for public good, you could do far worse than HeLa. It&#8217;s a ubiquitous cell line, after all, whose genome says a bit about cervical cancer; a bit more about how lab-farmed cells find ways to thrive; and, yes, a lot about Henrietta Lacks, who, suffering in rough conditions in a segregation-era cancer ward, made an unwitting, coerced, but remarkable bequest to human knowledge and health.</p>
<p>In these senses, the HeLa genome could anchor an engaging public panel discussion among geneticists, oncologists, ethicists, and, crucially, members of the Lacks family. Glibly, it might start with a bird&#8217;s eye look at cancer as <a href="/genomes-and-health/why-cancers-are-the-least-and-most-genetic-of-diseases#hive">doomed cellular mutiny</a>. Next, meeting Henrietta herself through family memory, we&#8217;d learn how her particular tumor <a href="/genomes-and-health/why-cancers-are-the-least-and-most-genetic-of-diseases#HeLa">eluded such doom</a> by appealing, ironically, to humanity&#8217;s needs. That notion raises the thorny ethics of using a useful but unethically obtained resource (with no direct recompense to the family who suffered most in giving it to the world), and in turn opens the meta-wormcan of genomic privacy. And new insights from the HeLa genome itself help weave these threads into emerging genomic portraits of the cell line and the little-sung woman it traces to.</p>
<p>As noted, such a discussion would most enlighten if it directly included members of the Lacks family, who could reflect personally on Henrietta, HeLa, and genetic privacy &#8212; and who embody how segments of her genome also live on, most vitally, in the kin she loved and would have loved.</p>
<p>Pat, yes. But HeLa&#8217;s genome clearly adds something to an already compelling tale &#8212; one that <a href="http://rebeccaskloot.com/">Rebecca Skloot</a>, who had <a href="http://www.jhu.edu/~jhumag/0400web/01.html">long been writing</a> about Lacks and her cells, soon told in much finer detail, in <em><a href="http://www.nytimes.com/2010/02/07/books/review/Margonelli-t.html?pagewanted=all">The Immortal Life of Henrietta Lacks</a></em>.</p>
<p>As that book makes clear, the HeLa saga has long blended travesty, triumph, and quandary in roughly equal parts. The debate over its genome is thus just a new eddy of an old storm. The last few months, like the previous 71 years, have seen useful data tainted by heedless ethics; public efforts to mend, if not undo, a wrong; and, perhaps most pressingly, lasting questions about how we should use scientific resources whose provenance is, at best, murky.</p>
<p>We haven&#8217;t dwelled here on how, in bypassing the Lackses, the first HeLa genome paper furthered a history of disregard for real <em>people</em> who carry forth Henrietta&#8217;s DNA, and who mourn her most deeply. Nor have we tried to define what genetic privacy means, given that far more of <em>any</em> genome is complicatedly shared &#8212; with kin, both known and unknown &#8212; than is truly private.</p>
<p>Rather, we&#8217;ve focused on the question of what we can indeed learn from a single genome, which matters for three main reasons.</p>
<p>First, the question cuts across the authors&#8217; initial claim that the genome of HeLa (read: any tumor or cell line) told us nothing about Henrietta Lacks (read: any person from whom such cells are taken). That technical claim doesn&#8217;t hold up, as we&#8217;ve seen.</p>
<p>Second, it points, more broadly, to what we can, and cannot, reasonably hope to learn today about a person just by looking at a genome. The paper itself confirmed, via HeLa&#8217;s genome, that Lacks was indeed a woman with largely west African and European ancestry. And some of us noted that we could go deeper, using <a href="http://www.1000genomes.org/">public data</a> to guess which variants were attached to which others in Lacks&#8217;s chromosomes, ultimately clarifying which parts of the world particular stretches of her genome trace to, and even which particular people are her close cousins in particular parts of the genome.</p>
<p>Moreover, the paper&#8217;s authors soon acknowledged that well studied variants that HeLa shares with other human genomes can let us guess at particular traits that Lacks may have had, and at various disease risks that she might have faced, had she not died of cervical cancer at thirty-one. But the bottom line on this front is that there&#8217;s still much we <em>can&#8217;t</em> guess from looking at one genome &#8212; even the <em>best</em> sequenced one. As more people&#8217;s genomes and traits are surveyed over time, however, the HeLa genome will indeed reveal deeper insights about who Lacks was. Facets of her uniqueness &#8212; voice and gait, quirks, ailments, and interests &#8212; may someday be traceable, in part, to distinctive genomic spellings that for now hide mum in plain sight.</p>
<p>Third, the technical question of what we can learn raises thornier <em>policy</em> questions about data privacy, ownership, publishing, and consent. And here, perhaps, likening HeLa&#8217;s genome to a remixed or cubist rendition of Lacks&#8217;s was apt. A person&#8217;s DNA uniquely quilts together genome segments shared with others (kin, both near and far), peppered with a few brand new variants (by mutation). As such, it&#8217;s neither fully original, nor fully derivative &#8212; like a work of art, necessarily influenced by broader culture. And, perhaps notably, tough questions about sampling and provenance (<a href="http://en.wikipedia.org/wiki/Elgin_Marbles">Elgin marbles</a>, anyone?) have long raged in the art world, with few clear answers. As such, prepare for a vocal, but likely indefinite societal conversation on that front.</p>
<p>[^1] The paper itself made this clear by showing, from HeLa’s genome, that Lacks was indeed a woman with largely west African and European ancestry. Some of us noted that we could go deeper, using public data to guess which variants were attached to which others in Lacks’s chromosomes, clarifying which parts of the world particular stretches of her genome trace to, and even which particular people are her close cousins in particular parts of the genome.</p>
<p>Moreover, some common variants that HeLa shares with other human genomes let us guess at traits that Lacks may have had, and at various disease risks that she might have faced, had she not died of cervical cancer at thirty-one.</p>
<p>[^2] In this sense, the HeLa genome controversy echoes recent debate over <a href="http://www.genome.gov/10005107">ENCODE</a>, an effort to survey which parts of our genomes govern how much of each protein gets made, where, and when. The ENCODE controversy has hinged, in part, on what the word <em>functional</em> means; for HeLa, the key question is what it means to &#8216;learn nothing&#8217; about a genome or person.</p>
<p>Note here that the HeLa authors might likewise have gone out of their way to tell us that we can learn &#8216;nothing about cell lines&#8217; from the HeLa genome. After all, it&#8217;s -possible- (though astoundingly unlikely) that the whole HeLa genome &#8212; triploid chromosomes and all &#8212; is exactly the same genome, letter for letter, that Lacks was born with.</p>
<p>[^3] While HeLa&#8217;s genome long intrigued me and others, several technical, funding, and strategic hurdles thwarted the idea back then. And here it bears note, at risk of sanctimony, that our brainstorming on HeLa was <em>always</em> premised on the blessing and direct participation of the Lacks family; had the project been green-lighted internally, step one would have been reaching out to them. So when I learned that the authors of the HeLa paper hadn&#8217;t engaged the Lackses, my heart, like others, sank&#8230;and when I then read the authors&#8217; original FAQ, which protested (too much) that their data said nothing about Lacks herself, my gorge rose, prompting this post.</p>
<hr />
<h2>Update (7 August 2013):</h2>
<p>Lacks&#8217;s descendants will <a href="http://www.nature.com/news/deal-done-over-hela-cell-line-1.13511">reportedly</a> anchor a new committee to consider, case-by-case, requests to use HeLa genome data in biomedical research. Brokered by the family, Skloot, <a href="https://en.wikipedia.org/wiki/Francis_Collins">Francis Collins</a>, and others, the arrangement won&#8217;t make the HeLa data fully open (so most useful), keeping it instead in NIH&#8217;s credential-walled <a href="http://www.ncbi.nlm.nih.gov/gap">dbGAP</a>. Nonetheless, it&#8217;s a gracious and scientifically substantive gesture by the family, whose preference understandably trumps other factors.</p>
<p>HeLa was, after all, derived surreptitiously from their own foremother (and, if all her descendants agreed, no one else&#8217;s) without informed consent. That wrong, along with the decades more of scientific ill-treatment of the Lackses that followed, remain the heart of the matter, even if the HeLa saga also highlights</p>
<ul>
<li>broader dilemmas around publishing genome data from explicitly named people, given that doing so makes it much easier to guess who else (their identifiable kin) likely carries many of their distinctive genetic spellings too.</li>
<li>more hearteningly, the potential benefits of directly engaging layfolk as partners in interpreting data they give for societal benefit</li>
</ul>
<p>For now, here&#8217;s to new discoveries that the soon-to-be accessible data will unlock, including those about Lacks herself. Happily that&#8217;s starting already: the data access plan itself was announced alongside a new <a href="http://www.nature.com/nature/journal/v500/n7461/full/nature12064.html">paper</a> dissecting the HeLa genome in unprecedented detail &#8212; notably, with phased haplotypes that should, as noted above, help us better guess which variants Lacks was indeed born with, and which arose only in the cells that became her tumor.</p>
]]></content:encoded>
		<wfw:commentRss>/2013/04/01/the-shock-of-the-new-what-we-can-say-about-helas-novel-variants/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Harmful by any other name: On clinical variant classification</title>
	<link>/2013/03/22/harmful-by-any-other-name-on-clinical-variant-classification-2/</link>
	<comments>/2013/03/22/harmful-by-any-other-name-on-clinical-variant-classification-2/#respond</comments>
	<pubDate>Fri, 22 Mar 2013 06:42:14 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genomes and health]]></category>

	<guid isPermaLink="false">/?p=70</guid>
	<description><![CDATA[In Phoenix this week, clinical geneticists have gathered at ACMG to catch up on health-relevant genomic findings and tools, and decide how to best put...]]></description>
		<content:encoded><![CDATA[<p>In Phoenix this week, clinical geneticists have gathered at <a href="http://www.acmgmeeting.net/acmg2013/public/enter.aspx">ACMG</a> to catch up on health-relevant genomic findings and tools, and decide how to best put them into broad practice. Tonight, in particular, features a workshop on how to classify DNA spelling variants, and report them to patients and caregivers. Chief among questions at hand will be what to <em>call</em> such variants.</p>
<p>Led by the ever-thoughtful <a href="http://www.bizjournals.com/boston/stories/2010/10/11/focus38.html">Heidi Rehm</a>, the workshop is a great chance to define a sensible set of classification bins that best convey how each genetic variant likely affects the health of a person who might carry it.</p>
<p>With an eye to that question, here&#8217;s the most widely used binning scheme, put forth by <a href="http://www.ncbi.nlm.nih.gov/pubmed/?term=21681106">Kearney <em>et al.</em></a>[1]:</p>
<ul>
<li>Pathogenic</li>
<li>Unknown significance, Likely pathogenic</li>
<li>Unknown significance</li>
<li>Unknown significance, Likely benign</li>
<li>Benign</li>
</ul>
<p>And here, with some explanation to follow below, is an alternative to kick around:</p>
<ul>
<li>Harmful</li>
<li>Likely harmful</li>
<li>Not yet interpretable</li>
<li>Likely harmless</li>
<li>Harmless
<ul>
<li>Family-relevant</li>
<li>Treatment-relevant</li>
</ul>
</li>
</ul>
<p>In weighing these two schemes, first note that Kearney&#8217;s thoughtfully builds on a legacy that&#8217;s deeply familiar to many clinical geneticists &#8212; and has proved a good, if imperfect, rubric for current use. But as we slowly integrate genomic insights into healthcare for ever more people, from birth to old age, Kearney&#8217;s shortcomings may limit its shelf life. Let&#8217;s review.</p>
<h2>What the Kearney scheme gets right</h2>
<p><em>It&#8217;s sensibly simple.</em> Importantly, Kearney (the first scheme above) sorts variants by our best guesses about how they affect health &#8212; and uses a plain word (<em>likely</em>) to neatly distinguish weak guesses from strong ones, without dickering about likelihoods of likelihoods. No arbitrary hair-splitting.</p>
<p><em>It&#8217;s realistically fluid.</em> By making uncertainty explicit, Kearney accomodates changing knowledge. A variant understood poorly today, but well tomorrow, can just be reclassified from the cautiously neutral middle of the rubric toward one of its poles &#8212; or back again.</p>
<p><em>It&#8217;s accurate.</em> Kearney implicitly uses the generalizable term <em>variant</em>, not alternatives like <em>mutation</em> and <em><a href="/concepts-genetics-jargon/polymorphism/">polymorphism</a></em>, whose usages have drifted in misleading ways. In the long run, this can help people understand their genomes accurately &#8212; more on that another time.</p>
<h2>What the Kearney scheme gets wrong</h2>
<p><em>It calls carrier variants pathogenic.</em> Some variants &#8212; <em>dominant</em> ones &#8212; cause disease if found on either of a person&#8217;s copies of a chromosome. But others &#8212; mostly <em>recessive</em> &#8212; do harm only if found on <em>each</em> of that person&#8217;s copies, or along with another variant elsewhere in the genome. Kearney lumps all such variants together, so a man with one copy of a dominant variant, one copy of an autosomal recessive variant, one copy of an X-linked recessive variant, and two copies of an ovarian cancer-causing variant, will misleadingly see all four identically called <em>pathogenic</em> in his report. This problem reflects how such schemes simplistically focus on <em>variants</em>, instead of <em>genotypes</em>. But, as we&#8217;ll see, they could nonetheless clarify which worrisome variants will or won&#8217;t make a given person sick. Moreover, distinguishing such variants can help us know which to watch for in other family members (especially future children, who might get copies from both parents, or who might crucially differ in sex from the parent who gave them a particular variant).</p>
<p><em>It says nothing about drug (or other treatment) response.</em> Beyond calling predictably harmless carrier variants <em>pathogenic,</em> Kearney&#8217;s scheme ignores variants that predict response to drugs and other disease treatments. Notably, such variants are, for now, among the most informative variants in our genomes &#8212; especially for fairly healthy adults (that is, those of us not <em>urgently</em> scanning our genomes for key insight into disease). As is, Kearney would thus glaringly omit key insight from a typical whole-genome report.</p>
<p><em>It&#8217;s unclear.</em> Like much medical jargon (see discussion below), Kearney uses fancy, euphemistic words from Greek and Latin (<em>pathogenic</em> = &#8216;sick-making&#8217;, <em>benign</em> = &#8216;good&#8217;) instead of plainer words understood by more people[3]. Given the bully pulpit that ACMG has at the dawn of genomic medicine, the scheme that it picks will likely shape how people learn about their health for years to come. As such, the jargon-versus-plain-English question is key: Will genome reports coddle <em>doctors</em> by sticking with the latinate jargon they love, or will we use plainer synonyms that <em>patients</em> too understand?</p>
<p><em>It&#8217;s awkward.</em> In the Kearney-inspired parlance of clinical geneticists, the ungainly phrase <em>Variant of Unknown Significance</em> has long stuck out like a Thumb of Unrelenting Soreness on a <a href="http://www.urbandictionary.com/define.php?term=R.O.U.S.">Rodent of Unusual Size</a>. Unlike the other bin names, <em>VUS</em> isn&#8217;t an adjective. Meanwhile, <em>pathogenic</em> and <em>benign</em> are odd antonyms, as the former may sound like it involves germs, and the latter more often opposes <em>malignant</em>, in describing tumors. Such inconsistency &#8212; and the whiffs of germ and cancer talk &#8212; may not help patients understand easily.</p>
<h2>An alternative</h2>
<p>With those shortcomings in mind, let&#8217;s review the newly proposed alternative scheme. While closely resembling Kearney, it arguably refines it in several ways.</p>
<p>First, by using plain words like <em>harmful</em> and <em>harmless</em>, it would be immediately clear to many layfolk, and avoid patronizing euphemism. As such, a fresh step toward empowering patients in the coming era of genomically informed healthcare.</p>
<p>Second, the proposed scheme comprises only adjectives &#8212; mostly short ones &#8212; with poles defined by simple <em>-ful</em> and <em>-less</em> antonyms[4]. The adjective phrase <em>not yet interpretable</em>, while still a bit awkward, plainly conveys both neutrality and openness to change.</p>
<p>Third, it highlights both carrier variants (<em>family-relevant</em>) and <em>treatment-relevant</em> variants in plain ways, accessible to both doctor and patient, that don&#8217;t unduly alarm or reassure. Note that while I&#8217;ve tentatively filed both new classes under <em>harmless</em>, based on their effects for the patient at hand, they don&#8217;t fit neatly there. Note too, that many drug response variants, in particular, may even be <em>helpful –</em> a category generally lumped in under <em>benign/harmless</em> in all these schemes.</p>
<p>At tonight&#8217;s workshop, I may float some of the ideas proposed here. While response may well be lukewarm at best, given the momentum that Kearney-like clinical genetics nomenclature has already gained, there may be no better time to speak up on the matter.</p>
<p>[1] The scheme was first proposed for variants involving long repetitive chunks of the genome, but has now been adopted more broadly.</p>
<p>[2] It&#8217;s worth asking, however, whether those two terms are too hard to uniquely abbreviate (<em>HF</em>? <em>HL</em>?), or would be readily confused in typing, reading, or speaking. If so, could an even shorter term like <em>OK</em> could sub for <em>harmless</em>?</p>
<p>[3] This habit likely dates to when Latin was the key shared language of European scholars – letting healers in, say, England, Italy, and Poland easily share new discoveries with each other.</p>
<p>Today, of course, science&#8217;s <a href="http://en.wikipedia.org/wiki/Lingua_franca">lingua franca</a> is English (and tomorrow perhaps Mandarin&#8230;). But while English taps two big stocks of words for the same things – pithy Germanic (<em>shit, yearly</em>) and flowery Greco-latinate (<em>excrement, annually</em>) – doctors (like lawyers and us scientists) find that continuing to cloak their work in layers of Greco-latinate jargon does three handy things.</p>
<p>First, it discourages DIY (or other) alternatives to their services. (<em>Ah, I have a contusion that may become a hematoma? Wow, thanks, doc – and I thought it was just a bad bruise&#8230;</em>).</p>
<p>Second, it hides knowledge from others – sometimes rightly (eavesdroppers in a hospital lift), sometimes not (an adult patient who wants frank talk, not patronizing euphemism).</p>
<p>Third, it binds them (well, us scientists too) in clubby solidarity, perhaps safeguarding a sense of prestige (<em>As we learned in med school, the reeeal word for right pinky is digitus minimus manus dextra&#8230;</em>).</p>
]]></content:encoded>
		<wfw:commentRss>/2013/03/22/harmful-by-any-other-name-on-clinical-variant-classification-2/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Genodicy: sequencing, in pain but in vain, to understand violence</title>
	<link>/2013/03/15/genodicy/</link>
	<comments>/2013/03/15/genodicy/#respond</comments>
	<pubDate>Fri, 15 Mar 2013 12:34:29 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genetics, evolution, and policy]]></category>

	<guid isPermaLink="false">/?p=34</guid>
	<description><![CDATA[Aftermath of Hurricane Sandy, Massachusetts (Image copyright Nathaniel Pearson) A journalist asked me last week to comment on reported plans to sequence &#8212; and ostensibly...]]></description>
		<content:encoded><![CDATA[<p><img src="/wp-content/uploads/2013/03/portal-3-1024x554.jpg" alt="" title="portal-3" /></p>
<p><strong>Aftermath of Hurricane Sandy, Massachusetts</strong> (Image copyright Nathaniel Pearson)</p>
<p>A journalist asked me last week to comment on <a href="http://www.nytimes.com/2012/12/25/science/scientists-to-seek-clues-to-violence-in-genome-of-gunman-in-newtown-conn.html">reported plans</a> to sequence &#8212; and ostensibly interpret &#8212; the genome of Adam Lanza, who killed 26 people in a Connecticut primary school last December.</p>
<p>When news of the pending Lanza sequencing originally hit, I was overseas with (thankfully) no internet access, so missed the ensuing <a href="https://twitter.com/search?q=lanza%20genome&amp;src=typd">chatter</a>. In particular, <a href="http://www.nature.com/news/no-easy-answer-1.12157">Nature</a> eloquently explained how such anecdotal genomics (<em>idiomics?</em>) soft-pedals the causal complexity of behavior &#8212; and could even risk stigmatizing people who share distinctive genetic variants, or phenotypes, with an infamous sequencee like Lanza.</p>
<p>While the ground here is thus well trod, please indulge a few more thoughts on the matter, starting with what I told the journalist:</p>
<blockquote><p>
  We already know, hands down, the best genetic predictor of human violence: it&#8217;s having a Y chromosome. And it&#8217;s an awful predictor; sensibly, we don&#8217;t lock people up for being male.</p>
<p>  Going further, to learn how <em>other</em> genetic variation helps govern behavior, will mean carefully studying <em>many</em> people&#8217;s genomes, and their traits and habits, over time.</p>
<p>  Only by doing so can we untangle how commoner, lifelong mental traits – some deemed normal, others not – interact with each other, and with social and other environmental factors, to shape our actions.</p>
<p>  That work will be soberingly tough. But however anxious we are to understand and prevent baffling acts like Lanza&#8217;s, we simply can&#8217;t make sense of one brutal outburst by looking at one genome.</p>
<p>  Thus the proposed study, however well meant, will likely be sadly futile. Lanza&#8217;s genome might be usefully interpreted only in a broader effort to first understand the roots not of mass murder, but of commoner, more readily studied mental traits – particularly, any well defined illness that he, like many other people who can also be sequenced, may have had.
</p></blockquote>
<p>Journalists live on red meat, so I tried to keep the foregoing short &#8212; by my windbag standards at least. Nonetheless, my comments will likely be whittled to a sentence or two, if published at all. But here I can pass them on in full, and even elaborate a bit.</p>
<p>It&#8217;s worth stressing, for example, that mental and behavioral problems we&#8217;ve already studied via many genomes &#8212; think depression, schizophrenia, autism, and such &#8212; have often proved, well, maddeningly hard to dissect. I&#8217;ll leave it to more informed voices to tell us which such phenotypes might, in turn, help predict otherwise apparently random violence (naively, is social withdrawal relevant?). But if any of them do, their own causal complexity likely only compounds the challenge of prophesying murder from the cradle.</p>
<p>We could likewise mull other questions hinted at in the quote about the project. Do such studies not only mislead, but risk eroding lay support for science? (Likely yes.) Does studying violence biologically <em>excuse</em> bigger factors like guns? (Not if done right &#8212; after all, we don&#8217;t grumble that sequencing lung tumors hampers anti-smoking efforts.) Can we learn anything about human violence by also considering not just environmental factors, but evolutionary insights too? (Likely yes, though beware pat answers (like this one).)</p>
<p>It&#8217;s the simple but telling Y chromosome point, however, that most bears fleshing out here. Namely, murderers indeed tend to be male; but murder is so much rarer than maleness that the predictive arrow really points upstream of where we&#8217;d like. That is, being a murderer strongly predicts having a Y chromosome &#8212; not vice-versa. Genomic <em>utility</em>? Add a failing <em>f</em> to the latter.</p>
<p>And that odds-making asymmetry dogs other, less fraught genetic insights too. Take a <a href="http://snpedia.com/index.php/ACTN3">well known dimorphism</a> in the length of <a href="http://en.wikipedia.org/wiki/ACTN3">alpha-actinin-3</a>, the protein encoded by our <em>ACTN3</em> gene. As first <a href="http://www.ncbi.nlm.nih.gov/pubmed/12879365">reported</a> by <a href="http://www.macarthurlab.org/">Daniel Macarthur</a> and colleagues in 2003, and affirmed in subsequent work by others, nearly every elite sprinter carries at least one copy of <em>ACTN3</em> that encodes a full-length version of the protein. But so, it turns out, do <em>most</em> people (yours truly excepted)! Yet how many of us are elite sprinters?</p>
<p>As such, <em>ACTN3</em> genotype hardly predicts medals. Rather, <em>medals strongly predict ACTN3 genotype</em>.</p>
<p>Picking a child&#8217;s afterschool sports via 23andme results thus might not be abusively cruel, but it&#8217;d certainly be foolish &#8212; and not just statistically. Given the vast, rich space of human personality and endeavor, and the scarcely scratched complexity of our genomes, pigeonholing someone by weak genomic associations understood today &#8212; or those yet to emerge from the murk of behavioral genomics &#8212; risks clipping otherwise powerful wings of individual drive, ability, and fulfillment.</p>
<p>And such questions of upbringing and personal complexity return us to Lanza&#8217;s genome &#8212; ultimately, to the question of what went wrong in his life, genetically or otherwise, that led him to brutally cut short so many others&#8217;. Sadly, sequencing his genome just grasps at <a href="http://www.wordnik.com/words/sideromancy">causal straw</a>, straining to trace a terrible act to some simple, reassuringly inevitable nugget.</p>
<p>If that wish echoes <a href="http://en.wikipedia.org/wiki/Theodicy">theodicy</a> in modern biological terms, we can at least take heart that our genomes, like no god, are real &#8212; so may eventually help better explain our brutality to each other. Because we work in <em>testably</em> mysterious ways, we can indeed hope to learn more about the genetic underpinnings of behavior than that maleness matters. But those better answers will take time &#8212; and, alas, far more than one genome &#8212; to find, to untangle, to absorb.</p>
<p><img src="/wp-content/uploads/2013/03/Leaves-1024x500.jpg" alt="" title="Leaves" /></p>
<p><strong>Leaves after Sandy, Massachusetts</strong> (Image copyright Nathaniel Pearson)</p>
]]></content:encoded>
		<wfw:commentRss>/2013/03/15/genodicy/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Third-generation sequencing</title>
	<link>/2012/08/30/third-generation-sequencing/</link>
	<comments>/2012/08/30/third-generation-sequencing/#respond</comments>
	<pubDate>Thu, 30 Aug 2012 19:49:57 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Seq: Reading DNA]]></category>

	<guid isPermaLink="false">/?p=63</guid>
	<description><![CDATA[By Gregory Snyder Since the completion of the Human Genome Project less than a decade ago, the cost of sequencing genomes has decreased more than...]]></description>
		<content:encoded><![CDATA[<p>By Gregory Snyder</p>
<p>Since the completion of the Human Genome Project less than a decade ago, the cost of sequencing genomes has decreased more than a thousand fold. This cost reduction has been accomplished by the rapid development of a &#8220;second generation&#8221; of DNA sequencing technologies to replace the methods used in the Human Genome Project. Lowering the cost another thousand fold, to less than $1000, promises to revolutionize medicine by enabling doctors to tailor strategies for disease prevention, diagnosis, and treatment to speciﬁc risk factors found in a patient&#8217;s personal genome. Moreover, low-cost genome sequencing promises to revolutionize basic research, too, by giving unprecedented complete information about the genetic structure of populations, which could yield insight in ﬁelds from epidemiology to evolution.</p>
<p>In a recent report in <em>Science</em>, Eid, et al. of Paciﬁc Biosciences (PacBio) demonstrate the proof of principle of a major step toward the affordable genome with a new method to sequence DNA cheaply and rapidly by watching an array of single DNA molecules being replicated in real time. PacBio succinctly refers to this capability as &#8220;SMRT,&#8221; for Single-Molecule sequencing in Real Time.</p>
<p>Recent introductions of products for second generation sequencing from Roche/454, Illumina, and ABI&#8211;all established players in the biotechnology world&#8211;have yielded a bumper crop of genome sequence from extinct animals (Neandertals and woolly mammoths), traditional experimental laboratory organisms (from mice to sea anemones), and individual human genomes (including those of famous genome scientists James Watson and Craig Venter). The impact of these technologies extends far beyond sequencing genomes, though. Many traditional methods for studying DNA and its interactions with other components of the cell are being reworked to take advantage of the power of these technologies to produce data that spans the entire genome, essentially letting scientists perform millions of separate experiments in parallel. The cost of this newfound experimental power and speed is, of course, monetary, and the more uses are found for second generation sequencing, the stronger the push will be to drive its cost down. And, in turn, the cheaper the technology becomes, the more its uses will proliferate.</p>
<p>Such is the pace of technological development that just as second generation products are beginning to establish themselves, their replacements are already emerging. One such &#8220;third generation&#8221; technology is the one just published by Paciﬁc Biosciences. Whereas the poor sensitivity of most sequencing technologies requires many identical copies of a DNA molecule to be made before its sequence can be found, the method described by Eid, et al. can sequence a single molecule of DNA. Single-molecule sequencing offers many advantages for the end user, including far lower consumption of chemical reagents&#8211;making the process cheaper&#8211;and faster and simpler sample preparation. What&#8217;s more, SMRT reads the sequence by watching a single strand of DNA be replicated in real time, at a rate of about ﬁve nucleotides per second, whereas other methods require complicated cyclical steps which take several minutes for each nucleotide addition. The total time needed to sequence a genome using SMRT could be days or even months less than that required by second generation technologies (depending on the size of the genome being sequenced and the method being used).</p>
<p>Achieving the exquisite sensitivity of sequencing single molecules of DNA required the development or optimization of several separate technologies. To start with, an appropriate means of detecting the DNA needed to be chosen. Given the current state of biophysical research, there was only one natural choice to be made, though the way in which SMRT utilizes it is novel in more than one way, as we will see in the coming paragraphs. That choice was to use ﬂuorescence, a phenomenon familiar to anyone who has worn a t-shirt in the last thirty years.</p>
<p>Fluorescence is particularly useful to biologists because they can attach ﬂuorescent dyes to biological molecules to be able to see them with a light microscope. Ordinarily, a single biological molecule, such as DNA, cannot be seen with a light microscope because light does not noticeably interact with objects that are much smaller than its wavelength. Visible light has wavelengths between 400 and 700 nm (nanometers, i.e., millionths of a millimeter), but the diameter of the double helix is only 2 nm. Fluorescent dyes are often slightly smaller than the diameter of helical DNA, but their peculiar electronic structure enables them to interact with light as if they were huge antennas. Attaching ﬂuorescent dyes to DNA lets scientists take advantage of centuries worth of technological advances in optics and results in a very sensitive detection method. Even current sequencing technologies make use of ﬂuorescent labels (they replaced the radioactive labels used in sequencing long ago, offering greater sensitivity and fewer dangers), but SMRT stands to make even more effective use of them by obtaining the ultimate sensitivity of detecting individual ﬂuorescent molecules.</p>
<p>Next, an appropriate polymerase had to be chosen for SMRT. A polymerase is a protein that generates the second strand of the DNA double helix from a single strand of DNA. Since the nucleotides in the two strands uniquely pair up according to rules called &#8220;Watson-Crick&#8221; base-pairing, knowing the sequence of one strand reveals the sequence of the other; the two strands are thus said to be &#8220;complementary.&#8221; Most sequencing methods, PacBio&#8217;s included, work by generating a complementary strand with nucleotides labeled by ﬂuorescent dyes that enable them to be detected and identiﬁed. For many technical reasons, it is impossible to sequence an entire genome (or even one chromosome) in a single stretch. Rather, a genome must be broken into overlapping fragments whose sequences can be computationally restitched together after they all have been obtained using the polymerase. All polymerases have a tendency to fall off of the &#8220;template&#8221; strand being replicated, but the stitching process works better when the fragments are longer. Polymerases which stay on the template longer are thus very valuable. PacBio chose the &#8220;φ29&#8221; polymerase because of its long average run length and modiﬁed it to increase its ability to use special ﬂuorescently labeled nucleotides.</p>
<p>The special nucleotides are the second major innovation which makes SMRT possible. The traditional place to attach a ﬂuorescent label to a nucleotide is near the part involved in forming a Watson-Crick pair. Each of the four nucleotides is labeled with a different ﬂuorescent dye so that a nucleotide may be identiﬁed by its color. The attachment can be made with a linker that is cleavable with chemicals so that the dye can be detached from the DNA after it has been detected, when it is no longer needed. On a second-generation sequencing machine using this kind of nucleotide, every time a position in the sequence is read, the machine has to remove the label in order to read the next position. It does so by ﬂowing the appropriate chemicals into the sample chamber, washing away the cleaved labels, and ﬂowing in the chemicals (including labeled nucleotides) needed to sequence the next base&#8211;a time-consuming and expensive process. In contrast, PacBio&#8217;s nucleotides are labeled on the &#8220;γ-phosphate,&#8221; the part of the nucleotide which is naturally cleaved off when it is incorporated into the strand of DNA being synthesized by a polymerase. Hence, SMRT does not require the cycling of different chemicals, and the polymerase is able to function naturally, as it would in the living organism it originally came from. This is the innovation that speeds up the chemical process of SMRT sequencing 30,000 times over second generation methods, enabling the sequence to be read in real time.</p>
<p>The third technology used in SMRT is the chip used to sequence many DNA fragments in parallel. It consists of a glass microscope cover slip with a 100 nm-thick layer of aluminum deposited on top of it. In the aluminum is an array of cylindrical wells 70 nm–100 nm in diameter. The aluminum is chemically treated so that polymerase molecules will stick to the glass at the bottom of each well rather than the sides of the wells. This is important because there is no way to manipulate a polymerase molecule to deliberately place it at the bottom of a well; rather the chip must be prepared by soaking it in a solution containing polymerase molecules, which then stick to every surface they can. The polymerase solution is very dilute, so that, on average, there is no more than one polymerase molecule per well. The cover glass at the bottom of the well permits an image of the activity of the polymerase at the bottom of each well to be projected onto a detector.</p>
<p>But why make the chip out of aluminum instead of plastic or a semiconductor? The answer forms the core of SMRT technology. A metal well with a diameter of 100 nm or less is called a &#8220;zero-mode waveguide&#8221; because the wavelength of visible light is too large to ﬁt into the well. Most of the volume of the well is completely dark for that reason. However, the physics of light works out such that when light is shone on the well, some of it is able to penetrate the entrance of the well, but only for 10 nm or so. 10 nm is just far enough to illuminate the polymerase at the bottom of the well. Illuminating the polymerase is necessary to excite the ﬂuorescent nucleotides as they are incorporated into the growing strand&#8211;the readout that reveals the sequence. (A ﬂuorescent T-shirt appears to glow because it is stained with a dye that absorbs light of a color that the human eye can&#8217;t see, i.e., ultraviolet light, and re-emits it as color the eye can see. But the T-shirt can not glow in complete darkness; ﬂuorescence requires excitation light.) During a SMRT sequencing run, each of the four DNA nucleotides must be available in solution in order for each polymerase to work. But since the nucleotides used for SMRT are all labeled with ﬂuorescent dyes, the solution would appear to be a glowing mass, and it would be impossible to see which nucleotide is being incorporated by the polymerase without the limited excitation volume generated by the zero-mode waveguide.</p>
<p>The ﬁnal clever trick used by Eid, et al. is to image the array of polymerases through a prism. The detector used for SMRT is very similar to the detector used in digital cameras. It consists of a light-sensitive semiconductor wafer divided into blocks, or pixels. Each pixel is sensitive to light of any color, and it only detects the brightness of the light striking it. Images from a digital camera are naturally grayscale. Digital cameras can only sense color because each pixel is covered with a red, green, or blue ﬁlter, and the electronics in the camera know which ﬁlter covers which pixel and can construct the ﬁnal image accordingly. Each pixel in the ﬁnal image from the camera is actually a composite of three pixels on the detector. But PacBio could not use a scheme like a digital camera&#8217;s, because ﬁlters necessarily throw away light: blue light incident on a red ﬁlter is absorbed before it can be detected. No matter how you slice it, single ﬂuorescent molecules do not emit very much light, so throwing away light in order to identify its color is unacceptable. Instead of throwing away light, a prism separates light of different colors in space. When seen through a prism, the image of a particular well in the SMRT chip will appear at a different location, depending on which nucleotide is being incorporated.</p>
<p>How well does it all work? After their article appeared in print, Paciﬁc Biosciences announced that they had sequenced the genome of <em>E. coli</em> &#8212; a bacterium commonly used as a tool in biological laboratories and ubiquitous in the digestive systems of mammals&#8211;with 99.9999% accuracy. Bacteria have much smaller and simpler genomes than humans, and they are routinely used to demonstrate a new technology, with the promise that the technology will one day be usable on humans.</p>
<p>Though sequencing a human genome by SMRT may still be a long way off, no second generation technology has been able to achieve such high accuracy. Moreover, PacBio has managed to achieve an average read length of almost 600 nucleotides&#8211;which is nearly as good as any existing technology and far better than most second generation technologies&#8211;and a maximum read length of more than 3000 bases. Such long read lengths eliminate the difficulty of assembling fragments from regions of repetitive sequence in a genome, a problem that hobbles second generation technologies. PacBio plans to ship its ﬁrst machine in 2010 and predicts that when the technology is fully developed, it will be capable of sequencing an entire human genome in about an hour.</p>
<p>Must third generation sequencing employ single-molecule detection? One company, Helicos Biosciences, has already based its second generation platform on cyclic sequencing of single molecules of DNA. However, Paciﬁc Biosciences&#8217;s chief competition in cost and throughput comes from Complete Genomics, whose technology also uses a second-generation, but non-single molecule strategy. Complete Genomics recently announced the sequencing of an entire human genome in a few days, in the process generating more than ten times the data that is possible with existing methods. Complete Genomics predicts its costs will decrease to levels similar to those Paciﬁc Biosciences hopes to achieve, but the company has been extremely guarded in releasing details for how it will attain its promised savings. Such stiff competition in the sequencing market is working to commodify genome sequencing, and the challenge is shifting from obtaining sequence data to understanding it. The transformation is well under way of the present &#8220;genomics&#8221; era, inaugurated by the completion of the Human Genome Project, into a &#8220;systems&#8221; era, in which the function of genes and their relationships will be studied in ways unimaginable a mere decade ago.</p>
<p>[Gregory Snyder, PhD, is a biologist living in Chicago.]</p>
]]></content:encoded>
		<wfw:commentRss>/2012/08/30/third-generation-sequencing/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>The myriad throng: Human effective population size</title>
	<link>/2012/06/24/the-myriad-throng-human-effective-population-size/</link>
	<comments>/2012/06/24/the-myriad-throng-human-effective-population-size/#respond</comments>
	<pubDate>Sun, 24 Jun 2012 10:42:34 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Evolution 101]]></category>

	<guid isPermaLink="false">/?p=46</guid>
	<description><![CDATA[Economy recapitulates demography? (image source) Iranians count their rials in superunits of the toman, from a Mongol word for ten thousand soldiers. Remarkably, such a...]]></description>
		<content:encoded><![CDATA[<p><img src="/wp-content/uploads/2012/06/10000-iranian-rial-zero-toman32.jpeg" alt="" title="toman" /></p>
<p><strong>Economy recapitulates demography?</strong> (<a href="http://gietalks.wordpress.com/2012/01/31/bills-for-thrills/10000-iranian-rial-zero-toman-2/">image source</a>) <a href="/humania-research-by-people-about-people-for-people/the-human-geneticist-at-large-notes-from-the-field/human-genetic-diversity-fieldwork-in-iran/">Iranians</a> count their <em>rials</em> in superunits of the <em>toman</em>, from a Mongol word for <a href="http://en.wikipedia.org/wiki/Tumen">ten thousand soldiers</a>. Remarkably, such a modest-sized horde could readily harbor much of the genetic diversity that long characterized people worldwide. But, with prices rising in Iran, a toman can <a href="http://en.wikipedia.org/wiki/Iranian_toman">reportedly</a> now mean ten <em>million</em> rials. And a new genetic census of humanity hints, likewise, at rampant inflation in our ranks&#8230;</p>
<p>Several weeks ago, we reviewed how a <a href="/genomes-and-health/rare-variants-disease-and-population-size/">newly documented trove</a> of rare variants in human genomes tracks our ballooning population. Most such variants, we saw, arose by recent mutations near the tips of our family tree &#8212; and now, like yuletide lights, mark out the tree&#8217;s fast-sprouting outer branches. The lengths of those branches, in turn, reflect a great proliferation of human ancestors as our population has exploded during the past few millenia.</p>
<p>But despite the rare variants that track our recent population growth, human genomes are still strikingly alike. Geneticists have long known, in particular, that two randomly chosen copies of a typical human chromosome tend to differ in spelling at less than one in a thousand letters.</p>
<p>Given what&#8217;s known about how fast DNA mutates, this is remarkably little variation. So little, in fact, that, despite our teeming numbers, the stock of variation in our genomes is, at first glance, roughly what we&#8217;d expect to find in a steady-sized population of just <em>ten thousand</em> randomly mating individuals.</p>
<p>So what gives? How can our genomes suggest a population that&#8217;s bursting the planet&#8217;s seams, yet small enough to gather in <a href="http://en.wikipedia.org/wiki/Centre_Court">Wimbledon Centre Court</a>?</p>
<p>Below we&#8217;ll learn how to guess directly at a population&#8217;s size from the profile of genetic variation that it carries, retracing how geneticists originally arrived at the ten thousand figure. And we&#8217;ll see how more nuanced math is revising our genetic census to better reflect the explosive growth that has loaded today&#8217;s billions of real human genomes with so many rare new variants.</p>
<h2>Consider a spherical gene pool&#8230;</h2>
<p>Geneticists use the term <a href="http://en.wikipedia.org/wiki/Effective_population_size">effective population size</a> to mean the number of idealized individuals who would typically harbor the same genetic diversity seen in a set of real organisms (whom the idealized ones &#8216;effectively&#8217; represent). In shorthand, this size is denoted <em>Nₑ</em>, where <em>N</em> stands for &#8216;number&#8217; and <em>e</em> stands for, well, &#8216;effective&#8217;.[1]</p>
<p>Ultimately, the concept of <em>Nₑ</em> is the kind of simplification that a physicist might make in predicting the arc of a cow launched from a circus cannon. Bear with me on this, ok?</p>
<p>A cow is a complex lump of stuff, and modeling its flight precisely, down to the last whisker, would take great knowledge and computing power. But, where reasonable, scientists like to lazily simplify things. So, rather than try to account for every cranny of the cow&#8217;s shape, every quirk of density and electric charge inside it, and every component of its motion (methane release-induced yaw&#8230;), a physicist might model the cow as a chargeless point mass flying in a vacuum.</p>
<p>Because such an idealized mass would fly in a simple path, immune to aerodynamic, electrostatic, buoyant (were this an underwater flight) or other such real-cow effects, it might be, say, a bit lighter than the real cow and still fly just as far. A physicist might think of that smaller mass as the &#8216;effective mass&#8217; of the cow.</p>
<p>Or, more realistically, our physicist might accept that cows fly through real air (or water), and have nonzero volume, and so model the cow (still simplistically, of course) as a symmetrical ball with the cow&#8217;s mass and net density. To the extent that the flight of such a ball approximated that of the real cow, the ball&#8217;s radius could be called the &#8216;effective radius&#8217; of the cow.</p>
<p>Geneticists can model the evolutionary trajectories of populations, on likewise simplistic lines. Rather than try to track (or guess precisely at) every detail of mating, fertility, migration, and mutation in a population&#8217;s history, they often make simple assumptions about those processes. And those assumptions, to the extent valid, can point to an &#8216;effective size&#8217; that gives a rough handle on how a given population is evolving.</p>
<h2>Happy little trees</h2>
<p>The link between population size and genetic variation can be seen most clearly through the lens of genealogical tree shape, as introduced <a href="/genomes-and-health/rare-variants-disease-and-population-size#tree-shape">here</a>.</p>
<p>To put hard numbers on that connection, let&#8217;s sketch the family tree of all copies of just one site in the genomes of a population. Taking a cue from the great <a href="http://www.nytimes.com/2001/11/18/arts/television/18MORF.html?pagewanted=all">Bob Ross</a>, we&#8217;ll paint our tree in simple strokes: it will represent a population of some big, <em>constant</em> number <em>N</em> individuals, who breed at most once, in discrete generations, blindly with respect to their genotypes, without complications from factors like <a href="http://en.wikipedia.org/wiki/Natural_selection">natural selection</a>, <a href="http://pritch.bsd.uchicago.edu/publications/pdfs/RosenbergEtAl02.pdf">geography</a>, or <a href="http://en.wikipedia.org/wiki/Genetic_recombination">recombination</a>.[2]</p>
<p>If these <em>N</em> idealized individuals have simple <a href="http://wikipedia.org/diploidy">two-copy</a> genomes like our own, then each site in those genomes has 2_N_ total copies in the population overall. The family tree for a given site then represents the ancestries of all 2_N_ copies as a skeletal graph, tracing how they&#8217;ve been copied from one generation to the next.</p>
<p>Now, here&#8217;s a crucial point about our model: we&#8217;ll stipulate that, looking back in time, toward the root of the tree, each copy of the site in a given generation traces back <em>at random</em> to one of the 2_N_ copies in the generation before &#8212; and does so regardless of whether any other copy also traces back to that same previous-generation copy.</p>
<p>This means that, while there are always 2_N_ copies of the site in the model population, only <em>some</em> of them, in any given generation, are copied into the next one. That is, a given copy today may give rise to more than one of tomorrow&#8217;s 2_N_ copies &#8212; while other copies, by chance, end up as evolutionary dead ends.[3]</p>
<p>And that sheer randomness is, ironically, where the math gets precisely predictive.</p>
<p><img src="/wp-content/uploads/2012/06/PastNowTree.png" alt="" title="tree" /></p>
<p>Tree (bold green) tracing the ancestry of a population of ten modern copies of a genomic site, amid branches of overall genealogy (gray) of constant-sized population. Arrows point forward in time, linking one generation to the next; coalescences are found by tracing lineages backward (toward left) til they meet. (figure adapted from <a href="http://www.stats.ox.ac.uk/~mcvean/L2slides4.pdf">lectures</a> by <a href="http://www.stats.ox.ac.uk/~mcvean/">Gil McVean</a>)</p>
<h2>Chance encounters</h2>
<p>Notice, in particular, that our simple model gives any two copies of the site in a given generation a one-in-2_N_ chance of tracing back to the same parent copy in the previous generation.</p>
<p>Because <em>N</em> is big, that chance is tiny. But (but!&#8230;) if we look back over enough generations, the lineages of those two copies will eventually meet at some shared ancestor. That is, chance dictates that they won&#8217;t forever keep tracing to separate ancestral copies, but at some point will happen to trace to the same one.</p>
<p>Such random lineage mergers &#8212; which geneticists call <a href="http://en.wikipedia.org/wiki/Coalescent_theory">coalescences</a> &#8212; are, in the end, why the family tree of the <em>2N</em> copies is indeed a tree, rather than just a bundle of 2_N_ endless, unconnected vines.</p>
<p>And, while the math in question looks hairy at first, it works out that, for big <em>N</em> under our simplistic assumptions, the <em>mean</em> number of generations that it takes two copies&#8217; lines to meet (looking back in time) approaches 2_N_. That is, the average time back to a merger becomes the reciprocal of the one-in-2_N_ chance of a merger in any single generation.</p>
<p>A neat, simple result.</p>
<p>Of course, if you use a computer to simulate the ancestries of many paired copies of the site under our model, you&#8217;ll find that the actual number of generations since coalescence varies randomly &#8212; a lot &#8212; around this average. But the average itself is nonetheless very handy.</p>
<h2>Mutations: buds on the branches</h2>
<p>In particular, knowing the average time separating two randomly chosen copies of a site means that, if we also know how often a typical copy <em>mutates</em> (randomly changes in DNA spelling), we can estimate how many mutations will most typically have happened along the two branches that, meandering back through time, ultimately unite the pair of copies.</p>
<p>Let&#8217;s use the letter <em>μ</em> for that per-generation, per-copy chance of mutation at the site. And we&#8217;ll note that, because each of the two branches that separate the paired copies of the site is, on average, 2_N_ or so generational copyings long, they tend to be separated by roughly 4_N_ generation-lengths overall.</p>
<p>With these simple observations, we can estimate the number of mutations that separate the two copies of the site as [drumroll&#8230;] 4_Nμ_.</p>
<p>Importantly, this number closely approximates the cornerstone measure of sequence variation in a population, <a href="http://en.wikipedia.org/wiki/Nucleotide_diversity">nucleotide diversity</a>, which we encountered <a href="/concepts-genetics-jargon/polymorphism-2/polymorphism-iii/">here</a>.[4]</p>
<p>And this result &#8212; that nucleotide diversity should be roughly 4_Nμ_ in our simple model population &#8212; is the basic nugget of insight that ties the historical size of a population directly to the pattern of genetic variation that it carries. That is, if we know two of the variables in question &#8212; nucleotide diversity and <em>μ</em> &#8212; we can in principle estimate the third variable, the size <em>N</em> of the population.</p>
<p>But recall that our simple model presumes the population to be steady-sized, with no natural selection, and so forth &#8212; conditions that don&#8217;t strictly hold in the real world. As such, like physicists modeling a flying cow, we&#8217;re actually using this simple 4_Nμ_ insight to estimate the population&#8217;s <em>effective</em> size, <em>Nₑ</em>.</p>
<h2>The few, the proud, the effective.</h2>
<p>So what, in the end, are the values of the two measurable variables, nucleotide diversity and <em>μ</em>, that suggest how many human genomes are &#8212; effectively &#8212; out there?</p>
<p>Depending on whom you look at, human nucleotide diversity ranges from roughly 0.0007 (for people who descend mainly from the fairly few ancient inhabitants of the Americas) to 0.001 (for people with recent ancestry in Africa, where we&#8217;ve been densely settled the longest, letting the most genetic diversity, <em>per capita</em>, arise and persist). That is, copies of human chromosomes tend to differ from each other at roughly seven to ten letters out of every ten thousand.</p>
<p>And <a href="http://johnhawks.net/weblog/reviews/genomics/variation/human-mutation-rate-review-2010.html">many</a> <a href="http://www.nature.com/ng/journal/v43/n7/full/ng.862.html">studies</a> of human and other DNA suggest that <em>μ</em> is roughly 1 to 3.5 x 10<sup>8</sup> per generation. That is, the genome of a viable human egg or sperm typically acquires a new spelling at roughly one letter per thirty to a hundred million.[5]</p>
<p>Putting these numbers together yields an estimate of human <em>Nₑ</em> at roughly ten (versus one or a hundred) thousand. Note that this is a back-of-the-envelope, order-of-magnitude kind of guess, and that it varies by what regional slice of humanity we look at (reflecting, in the end, real spatial variation in the longterm density of human settlement). More importantly, it clearly underestimates our real population size of roughly seven billion.[6]</p>
<p>And that difference is telling. Effective population size for any organism is typically less than the census size (and need not ever equal it), of course &#8212; that&#8217;s why it&#8217;s called &#8216;effective&#8217;, rather than &#8216;real&#8217;. But the fact that human <em>Nₑ</em> <em>per se</em> looks <em>so</em> low has long been a clue that our real population itself was long much smaller than it is now.[7] The newly documented glut of rare variants in our genomes strongly undergirds this idea, suggesting that very recently (in evolutionary terms) our population has grown much, much bigger.</p>
<p>As such, the overall data on human genetic variation clearly break the assumption of constant population size on which we simplistically estimated <em>Nₑ</em> in our simple model. But that estimate is stubbornly low for other reasons too.</p>
<p><img src="/wp-content/uploads/2012/07/Cypress-1.jpg" alt="" title="cypress" /></p>
<p><strong>Post-diluvian tree.</strong> Bald cypress with flood line, Carbondale, IL. (image copyright Nathaniel Pearson)</p>
<h2>Caution: Populations are bigger than they appear</h2>
<p>First, the trees generated by our model are, technically, most accurate for samples much smaller than the sampled population. As we look at more and more individuals, the model will tend to slightly <a href="http://www.sciencedirect.com/science/article/pii/S0040580905001498">underestimate</a> the lengths of the tree&#8217;s outermost branches &#8212; an effect that may contribute a (tiny) smidgen to the dilation of branches inferred in recent papers on the many rare variants found in samples comprising many thousands of people.</p>
<p>Second, and more importantly, most of the other hidden ways in which real populations can buck our über-simple model (besides change in size) tend to make them look even smaller. For example, a population comprising partly isolated sub-populations of various sizes, or one that undergoes the most common <a href="http://en.wikipedia.org/wiki/Directional_selection">kind</a> of natural selection, tends to look, in genetic terms, even smaller than we&#8217;d otherwise expect.[8]</p>
<p>Third, it turns out that, even if we realistically refine our simple model to let population size vary, the best longterm estimate of <em>Nₑ</em> roughly tracks the <a href="http://wikipedia.com/harmonic_mean">harmonic mean</a> of the population size over time &#8212; which in turn hews closely to the smallest value that the population passes through.</p>
<p>Thus, while our genomes do bear telltale signs of recent population growth, they also inevitably retain strong imprints of earlier eras when our ancestors were far fewer. Genetic diversity tends to be very sensitive to the demographic squeeze of a so-called population bottleneck &#8212; and it&#8217;s thought that our ancestors likely underwent one or, pending where they lived, even several severe ones.</p>
<h2>Grafting trees</h2>
<p>To better detect such a mix of population-size signals, geneticists can readily extend the basic coalescent model by dividing a genetic family tree into two or more parts, and modeling each in relative isolation.</p>
<p>They might, for example, single out one set of branches from the rest, to reflect the geographic isolation of some lineages from others (perhaps compounded by regional differences in sub-population size, natural selection, and so forth).</p>
<p>Or, more to our point, they could simply mark a height across the <em>whole</em> tree &#8212; like a flood mark on a mangrove or cypress &#8212; to specify a moment in the past when the size (or other evolutionary attributes) of the whole ancestral population changed.</p>
<p>In any such case, we get a tree that looks like multiple trees grafted together, as if by <a href="http://www.gutenberg.org/files/84/84-h/84-h.htm">Dr. Frankenstein</a>, to more realistically resemble the <em>true</em> genealogy of real copies of the genomic site in question.</p>
<p>If, for example, a population started growing at a marked time point, the resulting tree might have fairly stunted inner branches root-ward of that point, and longer outer branches leaf-ward of it. Conversely, if the population started shrinking at the chosen moment, the line drawn at the point in question would divide relatively stunted outer branches from longer inner ones.</p>
<p>Like master gardeners sculpting <a href="http://wikipedia.org/bonsai">bonsai</a> to the form of a wild tree, geneticists can tune their demographic assumptions &#8212; how big a population was originally, when and how fast it grew or shrank, <em>etc.</em> &#8212; to best fit their model trees to the real ancestral tree of copies of a genomic site.[9] As we&#8217;ve seen, the shape of that underlying genealogy is roughly discernible by measuring mutational differences among those copies, to proxy the lengths of the various ancestral branches that unite them.</p>
<p>Promisingly, the new papers on human rare variant burden use such tuning to re-estimate our effective population size to be on the order of <em>millions</em>, rather than mere thousands. <a href="http://www.ncbi.nlm.nih.gov/pubmed/22604720">Tennessen <em>et al.</em></a>, for example, estimate the modern effective population sizes of Africans and Europeans to both be roughly half a million each; and <a href="http://www.ncbi.nlm.nih.gov/pubmed/22582263">Keinan and Clark</a> estimate that European <em>Nₑ</em> is now roughly 1.1 million. Note that, in such estimates, exact numbers matter less than orders of magnitude. Models with so many parameters are easy to overfit &#8212; and human population history is obviously complex, defying any attempt to distill real demography to a simple trend in effective population size &#8212; so we shouldn&#8217;t demand especially precise inferences.</p>
<h2>The wheel&#8217;s still in spin</h2>
<p>Most importantly, the new papers make clear that the human population has likely grown even more quickly than exponentially in the past few millenia. Recalling our bovine ballistics analogy, we could liken such growth to a flying cow sprouting strikingly long, skinny legs.</p>
<p>Those legs weigh (and impede the wind) less than the bulk of its body, leaving the cow&#8217;s effective mass or radius somewhat smaller than we might expect, given the gangly havoc it would wreak in a china shop. But just as a calf&#8217;s growth spurt eventually leaves it much heavier, the recent population explosion that sowed our bumper crop of rare genetic variants may, in the long run, boost our effective population size tremendously.</p>
<p>That is, if we stably inhabit earth (or beyond) at or above our current density for a long time, many of our currently rare variants will, by chance or otherwise, become modestly common enough to distinguish many chromosomal copies from each other, pushing our nucleotide diversity well above today&#8217;s humble figures.[10] Our effective population size, as measured by overall diversity in our genomes, should then continue to shift toward a new, if elusive, equilibrium that more closely tracks our teeming numbers.</p>
<p>Along the way, our changing population size may shape public health in complex ways. In particular, a key question will be what happens to the likely sizable subset of newly arisen rare variants that pose health risks to people who carry them. As our population continues to skyrocket, more such variants will come into our midst.</p>
<p>At the same time, continued population growth should ultimately help natural selection purge such variants more efficiently than it can in a small population (where chance dominates the fate of variants, harmful or not).</p>
<p>But, to the extent that our future population growth itself depends on further advances in healthcare, we&#8217;ll also be altering the regime of such natural selection, ideally relaxing it in ways that help people live healthier lives no matter what variants they carry in their genomes.</p>
<p>If we can manage that, of course, we&#8217;ll have become an effective population in a deeper, more important sense yet.</p>
<p>[^1] Except under special conditions, <em>Nₑ</em> will be met or, more commonly, exceeded by the size of the real population.<br />
[^2] On the breed-at-most-once criterion, note that we&#8217;ll let them have more than one child per breeding episode &#8212; an important point, as we&#8217;ll see. Note too that we ignore some subtleties of mating itself, focusing more on ancestral chains of copyings of a genomic site than on the kinship of the individuals who carry those copies. The latter turns out to matter fairly little overall.<br />
[^3] Note that a given copy in one generation can end up as a dead end even if it <em>is</em> copied down into the next generation, if its lineage doesn&#8217;t make it into the <em>last</em> (<em>i.e.</em>, current) generation. Thus the heartwarming truism that you, and everyone you know, descend only from winners in the evolutionary game. In coalescent models, dead-end branches that don&#8217;t reach the current generation are typically ignored, simplifying the tree to just the skeleton that ties together all current copies of the site (which you can picture as the tree&#8217;s leaves).<br />
[^4] This holds if mutation is consistently very rare &#8212; and it generally is &#8212; so that the branches connecting the two copies of a site hardly ever harbor more than one mutation overall.<br />
[^5] A sperm tends to carry more new mutations than an egg does, however, in part because the average sperm derives from many more mutation-prone cell divisions in the body than the average egg does.<br />
[^6] Coincidentally, there are now roughly as many living people as letters in a human genome, if we include the <a href="http://en.wikipedia.org/wiki/Repeated_sequence_(DNA)">repetitive</a> and <a href="http://en.wikipedia.org/wiki/Heterochromatin">tightly bound up</a> genome segments that are especially hard to read.<br />
[^7] Natural selection, non-random mating, and other factors inevitably also play roles in that deviation, in ways that we&#8217;re still figuring out. Much research today aims to understand human evolution in fine strokes, focusing on particular parts of the genome (which may differ in their histories, reflecting their roles in disease, adaptation to particular environments, and so forth) and particular populations (which have split and merged in complex patterns that we can, by carefully surveying shared versus distinctive patterns of genetic variation, start to deduce in some detail).<br />
[^8] Notably, along these lines, the concept of effective population size itself conventionally presumes no natural selection at all. That is, the subscript <em>e</em> can effectively be read as &#8216;if there were no selection&#8217;. When geneticists do explicitly parametrize natural selection in relevant models, they typically drop the &#8216;effective&#8217; from the population size term (while still acknowledging that the remaining term <em>N</em> is a rough estimate). Distinguishing the conventional, singularly definitive <em>Nₑ</em> from other abstractions of population size turns out to be tricky in other complex (read: realistic) evolutionary scenarios too, such as when a population is split into subpopulations, with sporadic migration among them.<br />
[^9] Or, more often, a multi-site segment, which allows more precise measurement of differences among copies (though risks complication from <a href="http://en.wikipedia.org/wiki/Genetic_recombination">recombination</a> history).<br />
[^10] Strikingly, coarse, nucleotide diversity-based estimates of our effective population size are lower not just than those of, say, fruitflies &#8212; but even those of most other great apes, suggesting that, despite our current global prominence, they&#8217;ve outnumbered us for much of our history.</p>
]]></content:encoded>
		<wfw:commentRss>/2012/06/24/the-myriad-throng-human-effective-population-size/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Rare variants, disease, and population size</title>
	<link>/2012/05/28/rare-variants-disease-and-population-size/</link>
	<comments>/2012/05/28/rare-variants-disease-and-population-size/#respond</comments>
	<pubDate>Mon, 28 May 2012 15:33:10 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genomes and health]]></category>

	<guid isPermaLink="false">/?p=52</guid>
	<description><![CDATA[Three new papers spotlight a glut of rare variants in our genomes, with key insights for human history and health.]]></description>
		<content:encoded><![CDATA[<p><em>Three new papers spotlight a glut of rare variants in our genomes, with key insights for human history and health.</em></p>
<p><img src="/wp-content/uploads/2012/05/ginkobough-3.jpg" alt="Rare fruit burdens the boughs. Female gingko, Chicago<br /> (image copyright Nathaniel Pearson)&#8221; title=&#8221;ginkobough-3&#8243; /></p>
<p><strong>Rare fruit burdens the boughs.</strong> Female gingko, Chicago (image copyright Nathaniel Pearson)</p>
<h2>Rarity abounds</h2>
<p>Data-rich <a href="http://www.sciencemag.org/content/early/2012/05/21/science.1219240">new</a> <a href="http://www.sciencemag.org/content/early/2012/05/16/science.1217876">papers</a> from teams led by <a href="http://www.gs.washington.edu/faculty/akey.htm">Josh Akey</a> and <a href="http://www.eeb.ucla.edu/Faculty/Novembre/">John Novembre</a>, and a brief <a href="http://www.ncbi.nlm.nih.gov/pubmed/22582263">theory paper</a> from <a href="http://keinanlab.cb.bscb.cornell.edu/">Alon Keinan</a> and the prolific <a href="http://www.sciencemag.org/content/336/6082/740">Andy Clark</a>, highlight a bounty of rare genetic variants in our genomes &#8212; and point out why we should care.</p>
<p>Bolstered by the papers&#8217; data from more than 80 million copies of individual human genes, the growing catalog of such rare variants casts our recent ancestors&#8217; rampant population growth into sharper temporal relief &#8212; and should, in the long run, help finely trace the geographic sojourns of particular copies of human chromosome segments. More importantly, however, many of those rare variants likely figure centrally in our health.</p>
<p>These <a href="http://www.nature.com/ncomms/journal/v1/n8/full/ncomms1130.html">basic</a> <a href="http://www.nature.com/nrg/journal/v11/n6/abs/nrg2779.html">insights</a> have been clear to geneticists for a <a href="http://www.ege.fcen.uba.ar/materias/ecomolecular/Material/Coalescencia/bibliografia/mismatch_distribution.pdf">long</a> <a href="http://www.neurociencias.org.ve/cont-cursos-laboratorio-de-neurociencias-luz/SNPs.pdf">time</a>, and it&#8217;s great to see them percolate through the <a href="http://www.nytimes.com/2012/05/18/science/many-rare-mutations-may-underpin-diseases.html">lay press</a>. The new data papers scoured every letter of many genes in thousands of people, and found a bumper crop of spelling variants that are each found in just one or a few of those people. The third paper summarized what such findings suggest about precisely how big the human population has been over time, and roughly what they mean for efforts to understand disease.</p>
<p>Altogether, the findings cast such bright light on our origins and health because, under simple assumptions[1], geneticists can predict how often variants that do (or don&#8217;t) greatly alter proteins should pop up in a given proportion of people, if our ancestors were steady in number, and if proteins weren&#8217;t especially important for health. And those are two big ifs.</p>
<p>The new data highlight that <em>real</em> patterns of such variant frequencies in our genomes drastically flout those null expectations &#8212; and they call sensible attention to rare variants, which underlie that deviation, as we search for the genetic basis of disease. More specifically, the papers all underscore two broad insights that have been clear for several years:</p>
<ul>
<li>Our population has skyrocketed, but just for the past few millenia &#8212; a trend that&#8217;s left a strong signature of many young, rare spelling variants in our genomes.</p>
</li>
<li>
<p>Many of those rare variants may be making us sick.</p>
</li>
</ul>
<h2>A tippy tree, laden with rare fruit</h2>
<p>The findings in the new papers hinge on a simple insight: the more widely common a genetic variant is, the older it likely is. This is because old variants have typically been carried down many branches of the growing human family tree, spreading far and wide on the planet. By contrast, variants that just arose recently are typically confined to recently sprouted, geographically narrow branches of the tree.</p>
<p>While details of very early human population dynamics are hard to precisely infer[2], the new data, along with much other genetic and ancillary historical evidence (see Keinan and Clark&#8217;s reference citations, for starters), suggest that our population has grown extremely fast in the past few millenia. Such growth has, effectively, stretched the human family tree at its tips: the tree&#8217;s young twigs look longer[3], in units of generations, than we&#8217;d otherwise expect, given how long the trunk and inner branches are. And because new genetic variants pop up roughly randomly (by mutation) on the branches as they grow, the long, fast-growing tips of the tree harbor more of its total load of mutations than they would have, had the tree grown at a constant rate.</p>
<p>You can picture each such mutation as if it were a little brainstorm in the head of the late <a href="http://en.wikipedia.org/wiki/Dr._Seuss">Dr. Seuss</a>. Had Seuss drawn genomic family trees, he might have represented each mutation as an odd, never-before-seen kind of fruit, confined to the branch (big or small, and including its sub-branches) where the mutation struck. Many of the rife rare variants in our genomes can thus be thought of as distinctive fruits, each confined to just one or a few twigs amid a great, bushy tree.</p>
<p>In this light, the new papers affirm what&#8217;s become clear over the past few years, as we <a href="http://en.wikipedia.org/wiki/Whole_genome_sequencing">sequence more and more people&#8217;s whole genomes</a>: we&#8217;ll still be finding new human genetic variants for a long time, even after having sequenced many more of us.[4] And, as long as our population continues to dramatically balloon &#8212; a system out of equilibrium, in population genetic terms &#8212; the tree will continue to loosely resemble an <a href="http://en.wikipedia.org/wiki/Inflation_(cosmology)">inflationary universe</a>, its various branches speeding apart from each other via new mutations. In this analogy, the genetic counterpart of the <a href="http://en.wikipedia.org/wiki/Redshift">red-shift</a> that signals cosmic expansion is, roughly speaking, the overall <a href="http://en.wikipedia.org/wiki/Tajima%27s_D">skew in frequency</a>, toward rarity, of our genetic variants.</p>
<h2>Rare variants in disease</h2>
<p>Visions of the human family tree, tips bent toward our inquisitive grasp by newfound fruit, may recall the myth of <a href="http://www.wikipaintings.org/en/lucas-cranach-the-elder/fall-of-man-1537">another tree</a>. Apt, then, that the crop of rare variants in our genomes may include much of the fruit of human affliction.</p>
<p>Rare variants are thought to figure centrally in disease for two related reasons: as we&#8217;ve seen, most such variants are rare because they arose recently, so haven&#8217;t had time to spread widely among people; <em>and young variants, by definition, haven&#8217;t withstood natural selection for long.</em></p>
<p>Such selection &#8212; often assisted by chance &#8212; tends to keep harmful variants rare, or purge them from the population altogether. Non-harmful rare variants, by contrast, are in principle free to get more common (though chance often strikes them down too).</p>
<p>That is, over time, consistently harmful variants tend to vanish, especially if the population is big enough to stably harbor a rich variety of alternative variants; meanwhile, variants that happen <em>not</em> to harm their carriers are free to spread, whether by chance or, in rare cases, by helping their carriers have more kids than others do.</p>
<p>Together, these trends mean that a snapshot of the rare variants we carry today, like a minute&#8217;s worth of the world&#8217;s newest <a href="http://twitter.com/">tweets</a>, is likely enriched for items that will soon be either gone[5] or, in a few cases, more common.</p>
<p>And they help explain why surveys of the common genetic variants covered by fast, cheap <a href="http://en.wikipedia.org/wiki/SNP_genotyping#SNP_microarrays">SNP chip</a> screens rarely offer clear insight into disease risk. For a given stretch of the genome, such common variants do distinguish big branches of the human family tree from each other, making them quite informative of ancestry. But a consensus has emerged that the long tail of human genetic diversity &#8212; all those rare variants &#8212; is where we&#8217;ll find much of the genetic contribution to disease risk.</p>
<p>Spotting <em>which</em> rare variants harm us, however, turns out to be tough.</p>
<h2>Proof of burden</h2>
<p>Take the extreme case of a variant found in just one woman, among everyone on earth. If we split humanity into those who get a given disease in life, and those who don&#8217;t, our chosen woman must fall into one group or the other. And if we look at enough diseases, she&#8217;ll eventually fall into the sick group for at least one of them.</p>
<p>But it&#8217;s clearly too far a leap to infer that the unique variant she carries made her sick. That is, the variant&#8217;s distribution among people with and without the disease simply <em>can&#8217;t</em> be statistically significant, given how rare it is overall.</p>
<p>To meet this inherent challenge to squarely implicating a given rare variant in a given disease, geneticists look to leverage other insights. If the variant really is too rare to show up on further screening of more sick or healthy people &#8212; and that&#8217;s a place where the <a href="http://evs.gs.washington.edu/">new data</a> are already helping in my own work with researchers seeking to trace disease risks to variation in specific tracts of our genomes &#8212; they next ask how readily it may affect physiology by altering the amount or chemical makeup of a protein encoded by a gene that either harbors the variant itself, or sits near it in the genome.</p>
<p>And, next, they may look at more people with the disease in question, and ask whether <em>other</em> rare variants tend to cluster nearby in their genomes, moreso than other people&#8217;s. In recent years, as richly detailed data on human genetic variation has started to flow, geneticists have been honing <a href="http://genome.sph.umich.edu/wiki/Rare_variant_tests">rare variant burden tests</a> specifically to find such regions. Refining such tests, and gathering more genetic and phenotypic data to feed them, stands to bring many key insights into the genetic basis of disease (and on a time frame shorter, we can certainly hope, than that needed for natural selection itself to weed all those harmful variants from the crop of rare variants we carry!).</p>
<h2>A new drug</h2>
<p>To thoroughly catalog the rare variants that pepper our genomes, of course, we have to read what DNA letters we carry at each site in the genome, rather than just at those sites already known to vary in spelling (as in SNP chips). The newly published work furthers that effort, by carefully sifting through particular sets of genes in many thousands of people &#8212; more people than have ever been so comprehensively sequenced together.</p>
<p>Notably, the Novembre group&#8217;s paper focuses on a few hundred genes already thought to help govern how the body responds to particular drugs. Such genes are actually an intriguing testing ground for the notion that rare variants crucially shape not just disease risk, but other phenotypes (outward traits) too.</p>
<p>Many drugs derive from defense chemicals made by plants and molds &#8212; nature&#8217;s organic chemists extraordinaires &#8212; that our ancestors have long eaten, breathed, and otherwise touched. But modern folks have also tinkered greatly with such drugs, concentrating, combining, and diversifying them in our quest to prevent and cure diseases. As such, many drugs, and cocktails thereof, are (like other facets of our overall <a href="http://en.wikipedia.org/wiki/Thrifty_gene_hypothesis">diets</a>) fairly new parts of the human environment.</p>
<p>Drugs we take are thus exposing even the most <em>common</em> (read: oldest) variants in our genomes to novel regimes of natural selection. Many such drugs work better, at particular doses, in some people than others &#8212; and such variation may often trace largely to variation in our genomes.</p>
<p>Looking ahead, I&#8217;m intrigued to see whether rare genetic variants turn out to explain unusual responses to particular drugs as well (or better) as they explain particular diseases &#8212; or, alternatively, whether such variation in drug response traces largely to common variants in our genomes.</p>
<h2>Tall trees: the diversity skyline</h2>
<p>An intriguing tidbit in the Akey group&#8217;s paper is a spatial contour of overall genetic diversity across thousands of genes in our genomes. Plotting the classic measure of <a href="/concepts-genetics-jargon/polymorphism-2/polymorphism-iii/">nucleotide diversity</a> &#8212; that is, <em>how often two randomly chosen chromosomal copies of a genome site differ in spelling</em> &#8212; Akey&#8217;s post-doc <a href="http://www.gs.washington.edu/academics/postdocs/tennessen.htm">Jacob Tennessen</a> <em>et al.</em> predictably found the strongest peak in diversity in the <a href="http://en.wikipedia.org/wiki/Human_leukocyte_antigen">HLA</a> gene cluster on chromosome 6&#46; Expressed on the surface of immune response cells, these genes work, in large part, to help us fight infection &#8212; a job thought to be well served by great genetic diversity within a genome, which presumedly helps its carrier respond to many kinds of germs.</p>
<p>Byzantine in its sequence variation, HLA turns out to play surprising functional roles in mate choice, drug response, and diseases from <a href="http://www.ncbi.nlm.nih.gov/pubmed/22586495">multiple sclerosis</a> to <a href="http://www.ncbi.nlm.nih.gov/pubmed/17002906">narcolepsy</a>. Notably, women and other female great apes likely <a href="http://www.ncbi.nlm.nih.gov/pubmed/9326314">pick their mates</a> in part (and unconsciously) by how they smell, thanks partly to what versions of HLA they and their suitors carry. Such preferences are thought to help preserve genetic variation longer here than elsewhere in the genome &#8212; so well, in fact, that your copies of some HLA genes more closely resemble some gorillas&#8217; copies than some other people&#8217;s copies&#8230;and those gorillas&#8217; HLA genes are likewise closer to yours than to each others&#8217;!</p>
<p>Essentially, even the <em>inner</em> branches of the family tree of this part of the genome are <a href="http://www.ncbi.nlm.nih.gov/pubmed/8411099">incredibly long</a>, stretching back ten-fold more generations than is typical. As we&#8217;ll see in a coming post, the overall depth of the tree for a given part of the genome can be thought of as a rough proxy for how big the ancestral population for that part of the genome has, over time, tended to be.</p>
<p>Other peaks in genetic diversity &#8212; lower than HLA, but still prominent &#8212; include odorant receptor and keratin (hair/skin protein-making) genes, which are widely presumed to accumulate functionally unimportant variation, reflecting less stringent evolutionary constraint in people than in some other mammals. Strikingly, however, the Akey group also found that another immune response gene, <a href="http://www.genecards.org/cgi-bin/carddisp.pl?gene=DEFB108B"><em>DEFB108B</em></a>, marks a peak in genetic diversity roughly as tall as that of the much better known HLA cluster. It&#8217;ll be intriguing to learn more about what <em>DEFB108B</em> does in our bodies, and whether its remarkable diversity reflects HLA-like importance, or keratin-like dispensability.</p>
<p>Stay tuned on that front. As more of us are sequenced and phenotyped, we&#8217;ll learn much more about which of our variants &#8212; among the common ones, and the newly commonplace rare ones &#8212; matter most, and how. Much of what we learn will speak directly to the pending challenges of genomically personalized medicine, as framed in fervent discussion of another recent <a href="http://stm.sciencemag.org/content/4/133/133ra58.full.pdf">paper</a>, both at <a href="http://stm.sciencemag.org/content/4/135/135lr3">large</a>, and in <a href="/genomes-and-health/on-twins-genomes-and-health/">these</a> <a href="/genomes-and-health/why-cancers-are-the-least-and-most-genetic-of-diseases/">pages</a>.</p>
<p>[1] Back-of-the-envelope estimates typically ignore any complications from non-random mating, variation in mutation rate, and so forth &#8212; but are quite robust.</p>
<p>[2] Moreover, the history of human population change has, of course, varied in space (among regional sub-populations), as well as over time. Notably, the new papers suggest that such variation may be fairly minor in the grand scheme, dwarfed by the remarkable overall recent growth. And Keinan and Clark note that sample sizes, in particular, may add roughly as much noise to the picture as do real underlying variables.</p>
<p>[3] Ultimately, the length of these twigs tracks how long many randomly chosen pairs of extant copies of our chromosomes have descended along separate lines.</p>
<p>[4] In the end, you likely harbor a dozen or so brand new genetic variants that arose by mutation only in you. But you also likely harbor plenty of other very rare variants that, til we sequence your genome, will have never been spotted in anyone else.</p>
<p>[5] Note that this doesn&#8217;t mean that no one with harmful variants has kids &#8212; after all, <em>everyone</em> carries some such variants, and people are breeding just fine. Rather, because a given variant can be inherited independently of other variants in the same genome, and may wreak harm only in combination with another copy of itself (or some other variant), people simply tend to have more kids who inherit more copies of healthier alternative variants than kids who inherit more copies of harmful ones. Moreover, much of the natural selection in question likely happens beyond our view, before pregnancy begins, when unhealthy early embryos fail to implant and thrive in the womb.</p>
]]></content:encoded>
		<wfw:commentRss>/2012/05/28/rare-variants-disease-and-population-size/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	<item>
	<title>Why cancers are the least — and most — genetic of diseases</title>
	<link>/2012/04/19/why-cancers-are-the-least-and-most-genetic-of-diseases/</link>
	<comments>/2012/04/19/why-cancers-are-the-least-and-most-genetic-of-diseases/#respond</comments>
	<pubDate>Thu, 19 Apr 2012 13:28:16 +0000</pubDate>
	<dc:creator><![CDATA[Nathaniel Pearson]]></dc:creator>
		<category><![CDATA[Genomes and health]]></category>

	<guid isPermaLink="false">/?p=14</guid>
	<description><![CDATA[The plot thickens. The crab [&#8230;] only runs backwards. – Arsenio Rodríguez, Cangrejo Fue a Estudiar In time, finer data and statistical models will test...]]></description>
		<content:encoded><![CDATA[<blockquote><p>
  The plot thickens. The crab [&#8230;] only runs backwards.<br />
  – Arsenio Rodríguez, <em>Cangrejo Fue a Estudiar</em>
</p></blockquote>
<p>In time, finer data and statistical models will test the specific claims of a widely discussed recent <a href="http://stm.sciencemag.org/content/early/2012/04/02/scitranslmed.3003380">paper</a>, by Bert Vogelstein and colleagues, on the prospect of genomic risk prediction. Though the paper&#8217;s <a href="http://en.wikipedia.org/wiki/Meta-analysis">meta-analysis</a> of twin studies has taken some <a href="http://www.lastwordonnothing.com/2012/04/06/what-the-limits-of-dna-story-reveals-about-the-challenges-of-science-journalism-in-the-big-data-age/">heat</a> for repackaging longstanding knowledge about heritability, the fuss over it has usefully underscored real complexities of disease and healthcare. And <a href="http://www.genomesunzipped.org/2012/04/identical-twins-usually-do-not-die-from-the-same-thing.php">thoughtful responses</a> to the paper have made clearer, to the public, that few geneticists are the zealous determinists of caricature. Rather, we tend to grasp the causal basis of disease (and other phenotypes) with inclusive nuance.</p>
<p>But while the dialog may have enlightened many, both the paper and <a href="http://www.ucsf.edu/news/2012/04/11864/value-genomics-and-personalized-medicine-wrongly-downplayed">its</a> <a href="http://storify.com/Erika_Check/the-power-of-predictive-sequencing">critiques</a> have largely missed two pertinent points:</p>
<ol>
<li>In the world of genetic risk, cancers are big exceptions.</li>
<li>Inasmuch, they prove some underlying rules.</li>
</ol>
<p>And in the context of the paper itself, these points nestle into one nutshell:</p>
<blockquote><p>
  In research, twins with tumors are no longer really twins.
</p></blockquote>
<p>To see why, and fold this point into the wider discourse on genomically personalized healthcare, let&#8217;s peer briefly through the looking-glass of cancer genetics.</p>
<h2>Gemini, Cancer, and genomic horoscopes</h2>
<p>As <a href="/category/genomes-and-health/">noted</a>, the new paper aimed to summarize what studies of twins say about how well our genomes, alone, may predict what diseases we&#8217;ll get. The premise, of course, is that twins from the same fertilized egg resemble live runs of a telling thought experiment: <em>if you and your genome lived twice, would you get the same diseases?</em></p>
<p>The basic answer has long been clear: twins don&#8217;t always get sick the same way. But Vogelstein and colleagues reasonably asked, for particular common adult diseases, how often they <em>do</em>.</p>
<p>Sensibly, they reviewed available twin data for several complex (and interrelated) epidemic killers, such as <a href="http://www.mayoclinic.com/health/heart-disease/DS01120">heart disease</a>, <a href="http://www.mayoclinic.com/health/diabetes/DS01121">diabetes</a>, and <a href="http://www.mayoclinic.com/health/stroke/DS00150">stroke</a>. To boot, they also combed the literature on <a href="http://en.wikipedia.org/wiki/Dystocia">pregnancy complications</a> (an intriguing evolutionary nexus of health), some <a href="http://en.wikipedia.org/wiki/Central_nervous_system_disease">nerve</a> and <a href="http://en.wikipedia.org/wiki/Autoimmune_disease">autoimmune diseases</a>, and more mysterious ailments like <a href="http://www.mayoclinic.com/health/chronic-fatigue-syndrome/DS00395">chronic fatigue</a> and <a href="http://www.mayoclinic.com/health/irritable-bowel-syndrome/DS00106">irritable bowel</a> syndromes.</p>
<p>But nine of the twenty-four diseases they surveyed &#8212; <em>the bulk, by class</em> &#8212; were <a href="http://en.wikipedia.org/wiki/Cancer">cancers</a>. And this choice sapped any suspense from their findings. For while cancers indeed kill many people (so <em>demand</em> study), they are long known to be far less heritable &#8212; that is, to show a smaller portion of cases running in families &#8212; than many other grave diseases. As Vogelstein (a <a href="http://en.wikipedia.org/wiki/Bert_Vogelstein">renowned</a> cancer researcher) surely knows, loading a heritability survey with cancers is like padding a Russian presidential ballot with token dissidents. Conclusion: foregone.</p>
<p>To be fair, the authors likely didn&#8217;t set out to mislead. After all, they could only survey available studies of twins. And a <a href="http://www.nejm.org/doi/full/10.1056/NEJM200007133430201">big study</a> of cancers was ripe to include (in the end, it supplied all their data on the question). While that study did find some evidence of genetic heritability in cancers, it concluded that such heritability plays little role in most cases, bolstering the well-established bottom line: in the grand scheme, cancers rarely run in families.</p>
<p>Where the authors shouldn&#8217;t be excused so easily is in <em>a</em>) actively hyping their findings as novel, while <em>b</em>) burying this key grain of salt, far from headlines and press releases, in a brief aside near the end of the paper:</p>
<blockquote><p>
  For diseases with a lower heritable component, such as most forms of cancer, whole-genome based genetic tests will be even less informative.
</p></blockquote>
<p>Which any clinical geneticist could have told you, thirty years ago.</p>
<h2>And yet&#8230;</h2>
<p>Unsurprisingly, all nine surveyed cancers in Vogelstein&#8217;s survey were deemed less genetically predictable (heritable) than the other diseases studied. Nonetheless, any oncologist will tell you that cancers are <em>quintessentially</em> genetic diseases. As we&#8217;ll see, they require &#8212; and are even defined by &#8212; genomes gone awry.</p>
<p>Indeed, some of the most widely screened-for genetic risk variants underlie rare familial forms of <a href="http://www.cancer.gov/cancertopics/factsheet/Risk/BRCA">breast</a> and <a href="http://en.wikipedia.org/wiki/APC_(gene)">colon cancer</a>. And whole genome interpretation is finding its <a href="http://www.pbs.org/wgbh/nova/body/cracking-your-genetic-code.html">first vital clinical use</a> in treating tumors, along with sick children.</p>
<p>So what gives? How can cancers be intrinsically genetic, yet so hard to predict from our genomes?</p>
<p>The answer, it turns out, is that it matters which genomes we mean.</p>
<h2>The hive within</h2>
<p>To understand cancer&#8217;s peculiar nature as a genetic disease, first picture your body&#8230;as a colony of bees.</p>
<p>Bear with me here: both entities &#8212; you and the swarm &#8212; are, ultimately, teeming masses of individuals (cells or bees), most of whom work hard to help just a few of their kind (eggs or sperm, or the hive&#8217;s queen and few males) breed on their behalf.</p>
<p>In this view, the two basic kinds of cells in your body &#8212; gametes (which biologists also call the <a href="http://en.wikipedia.org/wiki/Germline">germline</a>) and <a href="http://en.wikipedia.org/wiki/Somatic_cell">somatic</a> cells &#8212; respectively resemble a bee colony&#8217;s two main <a href="http://www.dummies.com/how-to/content/how-to-identify-the-three-castes-of-bees.html">castes</a>, breeders and workers.</p>
<p>In a sexual many-celled organism, like you, somatic cells vary kaleidoscopically in form, embodying the many specialized tissues that that help a body thrive from moment to moment. Gametes, by contrast, specialize mainly in storing DNA for coming generations, and &#8212; as big, slow, costly eggs, or small, fast, cheap sperm &#8212; in finding a partner gamete to merge with.</p>
<p>In most animals, the cells that become the germline split from other cells very early in embryonic development. As with bee royalty, it&#8217;s nearly impossible for a somatic commoner to infiltrate their reproductively privileged ranks later.</p>
<p>While details prompt <a href="http://whyevolutionistrue.wordpress.com/2010/08/30/a-misguided-attack-on-kin-selection/">debate</a>[1], natural selection is thought to have driven the emergence of the soma-germline and worker-queen distinctions, and in both cases to have brokered a lasting <a href="http://en.wikipedia.org/wiki/Eusociality">social</a> <a href="http://en.wikipedia.org/wiki/Social_compact">compact</a> between the two kinds of individuals.</p>
<p>In this contract, a somatic cell in your hand, like a dutiful worker bee, effectively says to your gametes</p>
<blockquote><p>
  <em>Cousins, if you spread our shared genes, I&#8217;ll give my life to help you. Count on me to build sturdy shelter, find good food, fend off attackers, write honeyed words to entice a mate, and care tenderly for the children that come after. You do the rest, and send our line forth.</em>
</p></blockquote>
<p>Seen in this <a href="http://en.wikipedia.org/wiki/Social_contract#Thomas_Hobbes.27_Leviathan_.281651.29">Hobbesian</a> light, a tumor is, effectively, a mutiny of somatic cells, who break that evolutionary covenant with their germline cousins. A budding tumor cell effectively says &#8216;Hell no, I won&#8217;t work and die for other cells &#8212; I&#8217;ll reproduce, myself, instead,&#8217; and starts proliferating unchecked.[2]</p>
<h2>A disease of genomes</h2>
<p>Crucially, the cellular treachery of each cancer case typically traces to one or more sudden changes &#8212; mutations &#8212; in the genome of a somatic cell. The mutations in question may be slight &#8212; say, the miscopying of one DNA letter from the parent cell&#8217;s genome. Or they may be drastic, as when a rogue gamma ray shatters a whole chromosome. In the latter case, the cell may, in mending the resulting fragments of DNA, inadvertently scramble them.</p>
<p>Whether slightly or severely altering DNA sequence, the mutations that turn cells into tumors tend to do so in particular ways. Typically, they either throw, or freeze stuck, one or more functional switches in the budding tumor cell&#8217;s genome &#8212; switches that had, til then, tightly governed the reproduction of that cell&#8217;s immediate ancestors, yoking their proliferation to the overall best interests of the developing body.</p>
<p>The switches in question are often protein-coding genes that directly govern <em>a</em>) whether a cell divides or, instead, takes a moribund, tissue-specific form; and/or <em>b</em>) how the cell exchanges signals with other cells, <em>e.g.</em>, halting growth at the touch of a neighboring cell, or telling that neighbor to build more blood vessels, to bring more food and oxygen. In some cases, the key switch may govern how well the cell corrects DNA copying errors; one mutation in such a gene may thus spark many more, some of which eventually knock out other switches that more directly reined in the cell&#8217;s growth.</p>
<p>In the end, a tumor grows unchecked thanks directly to one or more newly arisen genetic variants that distinguish it from other cells in the same body.[3] Importantly, such cellular mutinies are (with some exceptions[4]) typically doomed: in their greed for resources, the rebelling cells weaken the body overall, and, with no way to escape, sink with the ship that they&#8217;ve commandeered.</p>
<h2><em>Sui genetis</em></h2>
<p>All this switch-throwing ultimately means that tumors grow, spread, and kill <em>specifically because their genomes differ from other genomes</em>. As such, cancers are not just genetic in origin, but break a key assumption underlying Vogelstein&#8217;s paper: that monozygotic twins are genetically identical.</p>
<p>That is, as soon as a person is diagnosed with a tumor, all bets premised on her genetic identity – or even near identity – to a twin are off.[5] Not only do billions of her cells now differ genetically from those of her twin, but they differ in ways that are, by definition, biologically <em>important</em>. That is, the distinctive genetic variants in question drastically change the way that cells work, letting them divide unchecked.</p>
<p>In this sense, a tumor genetically distinguishes its host &#8212; of whom it is intrinsically part &#8212; from other people <em>de facto</em>, much as inherited genetic variants may distinguish someone with a strongly heritable disease from other people. Notably, this insight tempers any expectation that the person&#8217;s twin should get the same disease (a cancer driven by genetic variants that the twin likely doesn&#8217;t carry). And it underscores the uniformitarian rule that cancers, in their poor heritability, seem at first to violate: <em>in diseases of all stripes, genomic differences matter</em>.</p>
<h2>Tumor genomes: noisy, mixed, changing</h2>
<p>The first active clinical uses of whole genome sequencing have been in pediatrics and oncology. And this makes sense. In bluntly formal terms, sick kids and tumors are both masses of cells &#8212; one beloved, the other loathed &#8212; that are growing awry. And they&#8217;re both growing, as such, too fast for us to wait for sequencing to get cheaper, or for medical knowledge to get deeper. We&#8217;ll sequence <em>now</em>, if we can afford to, in order to gain some foothold into the medical mystery at hand.</p>
<p>For tumors in particular, we hope that sequencing the tumor (and, importantly, healthy tissue for comparison) will reveal key genetic clues to how it arose, grows, <a href="http://en.wikipedia.org/wiki/Metastasis">spreads</a>, and might be slowed or killed. Alas that turns out to be hard to do, for three key reasons.</p>
<p>First, as noted, tumor genomes are pocked by mutation. Small spelling changes often abound, hiding a few functionally important ones (called <em>drivers</em>) in a cacophony of incidental noise (<em>passengers</em>). And, at bigger scales, long segments of chromosomes are often repeated, missing, or scrambled. Such rampant genetic variation is not just tough to functionally interpret, but also makes it hard to draw an accurate picture of the genome in the first place. Why? It turns out that the computer algorithms used in modern sequencing work poorly for genomes that differ greatly from the standard reference genome, because snippets of raw sequence data that don&#8217;t match up well to that genome (like puzzle pieces that don&#8217;t closely match the picture on the box) are hard to correctly place. Moreover, tracts of DNA letters that appear in multiple spots in a genome (like uniform fenceposts in a farmscape puzzle) are especially hard to accurately sequence &#8212; an acute challenge in tumors, where rampant mutational copying, cutting, and pasting turns the genome into a bewildering <a href="http://www.nature.com/nature/journal/v483/n7391/full/nature10910.html">house of broken mirrors</a>.</p>
<p>Second, each tumor actually harbors not one, but a <em>mix</em>, of such noisy genomes &#8212; often with non-tumor cell genomes inadvertently mixed in. While a tumor is indeed a clump of closely related cells that distinctively share particular variants, it&#8217;s also a <em>population</em> of genetically varied cell lines, each effectively striving to grow faster than the others, thanks to its own secondary stock of functionally relevant variants. But because sequencing today requires pooling many cells, genetic variation in the tumor tends to get homogenized, as if in a blender. An important variant carried only in a few cells may not be prominent enough to show up in the final reckoning of a singular tumor genome sequence.</p>
<p>Third, the mix of genomes in the tumor <em>evolves</em>, partly in response to treatment. Thus we may want to track how treating the tumor with a particular regimen kills of some cell lines in the tumor, while letting other lines, by chance resistant to the treatment, spread quickly. To best characterize and treat a tumor, we might want to see a <em>movie</em>, rather than just a snapshot, of its mix of genomes, letting us watch how they change in response to treatment. But doing so is, for the foregoing reasons, tough &#8212; and will be until we can sequence fewer cells at a time, for less money, and with longer snippets of raw sequence (analogous to bigger puzzle pieces that can be more reliably pieced together to get the whole moving picture).</p>
<h2>Epilogue</h2>
<p>On a late summer afternoon when I was six, my mom came to my room, sat next to me, and showed me fresh bruises on her arms and legs. Speaking with determined nonchalance, she trained a young boy&#8217;s restless attention to a moment of revelation.</p>
<p>Each squall-blush in her skin was, I learned, real bloodshed from a war below. In the marrow of her bones, delinquent cells were teeming, wrecking the nurseries of sticky <a href="http://en.wikipedia.org/wiki/Platelet">platelets</a> that she needed to heal small, everyday blood vessel leaks. The bruises were collateral damage from that mutiny &#8212; her own cells betraying her, and those she loved.</p>
<p>She sought treatment, but <a href="http://www.mayoclinic.com/health/leukemia/DS00351">leukemia</a> wore her down quickly. On Halloween night, muted by breathing tubes in intensive care, she could welcome my visit only with a tiny nod and a waiting cup of candy. She died a few days later, at 34&#46; My first-grade classmates, struggling to comprehend from afar, sketched colorful cards of condolence that I still keep.</p>
<p>Writing today, on her birthday, I&#8217;m older than she got to be. Childhood reading, long before Vogelstein&#8217;s paper, taught me that leukemia shows little heritability. Yet I still watch for bruises&#8230;and admit to a tinge of affirmed relief that, among the diseases that the paper assayed for genetic predictability, leukemia came in last.</p>
<p>But the comfort is cold. Cancers remain an especially vexing kind of plague: sprung from our own selves, tumors are, in the paper&#8217;s geminal terms, something like evil conjoined twins. Growing relentlessly, ever changing, they cloak genomic secrets in genomic smoke, and evade our harshest treatments. They are the last horcrux.</p>
<p>At a recent conference, I listened to Washington University&#8217;s <a href="http://genome.wustl.edu/people/mardis_elaine">Elaine Mardis</a> explain how she and her colleagues are systematically characterizing the genomes of thousands of tumors. Their yeoman work is building a broadly useful critical mass of detailed knowledge about how tumors arise, grow, and spread. But their findings are also helping real doctors and patients, today, choose treatments that lengthen lives and lessen suffering.</p>
<p>After Mardis&#8217;s talk, I told her how touched I am not just by her team&#8217;s work itself, but to know that <a href="http://genome.wustl.edu/">Wash U</a> (where my mom earned her <a href="http://books.google.com/books/about/Marriage_in_the_Novels_of_Arnold_Bennett.html?id=maj6tgAACAAJ">PhD</a>) and Barnes Hospital (where she gave birth to me, and died) now spearhead a data-driven fight against leukemia and other cancers.</p>
<p>And I&#8217;m proud that my own work at <a href="http://www.knome.com/">Knome</a> supports such efforts. By thoroughly characterizing tumor genomes, and developing algorithms to do so better, we&#8217;re helping clinical researchers spot genetic variants that directly drive tumor growth or, more rarely, predispose some families to recurrent cancers. That work, like Mardis&#8217;s, is already leveraging individuated genome data to help people live longer.</p>
<p>Looking ahead, those of us lucky enough to afford good healthcare today will likely be talking a lot about tumor genomes, with our families and friends, in coming decades. Relevant insights will likely guide vital choices for many of us and those we love.</p>
<p>We&#8217;ll see how soon other major adult diseases &#8212; think of those surveyed by Vogelstein <em>et al.</em>, but also of liver and kidney diseases, mental illnesses, breathing problems (asthma, respiratory tract infections), bone diseases, <em>etc</em>. &#8212; likewise become more amenable to personal genomic insights, first for diagnosis, and, in the long run, for prognosis too. Here&#8217;s to those twin prospects.</p>
<p>[1] In bees (as well as ants and termites), this compact is thought to be reinforced by the fact that a queen and her worker sister may be especially closely related &#8212; often moreso than either would be to her own daughter. This odd twist of kinship follows from male bees having just one copy of each chromosome (having hatched from unfertilized eggs), while females have two (hatching from fertilized eggs). As a result, bee full sisters share, on average, three-fourths of their DNA with each other, while mothers and daughters share just half.</p>
<p>In a real hive, the numbers are complicated by many pairs of workers being just half-sisters (with different dads). But that turns out not to matter much; the strong social contract of eusociality can be mathematically understood even without the extra-closeknit kinship that bee sisters share.</p>
<p>[2] As in many personified examples of rivalry between organisms, the tumor cell&#8217;s effective strategy is not conscious, but rather a mathematical truism &#8212; that is, cells in which a chance mutation tears the web of reproductive constraint that natural selection has woven will, at least in the short term, tend to outgrow neighboring cells.</p>
<p>[3] Importantly, a person may be born with at least one such genetic switch already thrown; this scenario underlies rare cases of strong familial cancer risk. Cancer can then strike as soon as a second switch &#8212; a copy of the same gene, or another gene &#8212; is randomly thrown by a new mutation.</p>
<p>People born with one broken copy of the cell growth-suppressing <em>RB1</em> gene, for example, tend to eventually get tumors in both eyes. In such cases, their working second copy of <em>RB1</em> tends to eventually mutate in one of the fast-dividing, light-bombarded cells of the retina of one eye, leading to a first tumor. Later, a second such mutation may strike a retinal cell in the other eye, spawning a tumor there too.</p>
<p>Thus even in rare forms of cancers that run in families, getting a tumor requires some new mutation in a somatic cell. And that mutation may, in turn, be driven by some environmental factor (such as radiation, toxins, or even infectious germs), highlighting that both genetic and environmental factors are key to understanding cancers &#8212; just as in other diseases.</p>
<p>[4] One tumor that beat the odds, living on beyond its original victim, belonged to American <a href="http://en.wikipedia.org/wiki/Henrietta_Lacks">Henrietta Lacks</a>. As detailed in Rebecca Skloot&#8217;s compelling <a href="http://rebeccaskloot.com/the-immortal-life/">personal and cellular biography</a>, in 1951, Lacks&#8217;s doctor took cells, without her consent, from the ovarian tumor that was killing her, and grew them in dishes. Though born in suffering and scientific misconduct, those cells nonetheless proved remarkably resilient in laboratory culture, and have since spread worldwide as a key resource for six decades of biomedical research.</p>
<p>Another tumor that slipped the mortal coil of its origins is the contagious facial cancer that plagues Tasmanian devils &#8212; the subject of a fascinating recent <a href="http://www.cell.com/retrieve/pii/S0092867412000815">paper</a>. And some rare <a href="http://www.plosgenetics.org/article/info%3Adoi%2F10.1371%2Fjournal.pgen.1002420">cancers of <em>germline</em></a> (rather than somatic) cells may manage to make gametes healthy enough to transmit themselves &#8212; rampant cell growth and all &#8212; to coming generations.</p>
<p>[5] Of course, even monozygotic twins without tumors aren&#8217;t really genetically identical. The genome&#8217;s great size, and the many generations of mutation-prone cell division needed to build the myriad cells in their bodies, nearly assure that no single cell in either one is genetically identical to the fertilized egg from which they came &#8212; much less to a typical cell pulled from the other twin.</p>
<p>But tumors flout the genetic identity assumption of twin studies even more severely. The many cells that make up a tumor tend to be especially closely related to each other, thanks to their recent growth spurt. Thus the newly arisen genetic variants that the tumors&#8217; cells share, and that distinguish them from other cells in the body (and even moreso from cells of the other twin, thanks to the extra rounds of cell division that separate the two cell lineages in question), are especially common among the cells of the person overall. As such, if we think of a person&#8217;s genome as comprising, at each site, a weighted mix of the genotypes of all her cells, then a tumor makes her particularly genetically distinctive &#8212; even beyond the prospect that those differences may be more functionally important in tumors than in other kinds of cells.</p>
]]></content:encoded>
		<wfw:commentRss>/2012/04/19/why-cancers-are-the-least-and-most-genetic-of-diseases/feed/</wfw:commentRss>
	<slash:comments>0</slash:comments>
	</item>
	</channel>
</rss>
